{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import floor\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from scipy.integrate import odeint\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm for splitting the dataset into training and validation \n",
    "def split(X,Y,porcent): #porcent must be between 0 and 1, it is the asigned porcent to the training dataset.\n",
    "    n=floor(porcent*len(X))\n",
    "    index=random.sample(range(len(X)),n)\n",
    "    X_learn=[]\n",
    "    Y_learn=[]\n",
    "    for i in index:\n",
    "        X_learn.append(X[i])\n",
    "        Y_learn.append(Y[i])\n",
    "    X_val=np.delete(X,index, axis=0)\n",
    "    Y_val=np.delete(Y,index, axis=0)\n",
    "    \n",
    "    X_learn=np.array(X_learn)\n",
    "    Y_learn=np.array(Y_learn)\n",
    "    return X_learn,Y_learn,X_val,Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_m=np.arange(0.1,0.51,0.01)\n",
    "H_0=np.arange(66,81,1)\n",
    "t=np.linspace(0,-12,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RHS(Omega_i, lna, gamma=0):\n",
    "    x, y, z, H = Omega_i\n",
    "    #x, y, z = Omega_i\n",
    "    pi = 3*x + 4*y\n",
    "    return [x*(-3 + pi), y*(-4 + pi), z*pi, -0.5*H*pi]\n",
    "    #return [x*(-3 + pi), y*(-4 + pi), z*pi]\n",
    "\n",
    "def EDO(t,Om,H0):\n",
    "    #t,Or,Om,Ol=X\n",
    "    Or=0.0001\n",
    "    Ol=1-Or-Om\n",
    "    #H0 = 70.\n",
    "    y0 = [Om, Or, Ol, H0]\n",
    "    result = odeint(RHS, y0, t)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets generate the cartesian product between the intervals\n",
    "Y0=[]\n",
    "#este ciclo llena la lista fijando un Om y pasando todos los Or\n",
    "for i in O_m:\n",
    "    for j in H_0:\n",
    "        Y0.extend(EDO(t,i,j))\n",
    "Y0=np.array(Y0)\n",
    "\n",
    "X0=[]\n",
    "for Om in O_m:\n",
    "    for H0 in H_0:\n",
    "        for T in t:\n",
    "            X0.append([T,Om,H0])\n",
    "X0=np.array(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "Y2 = scaler.fit_transform(Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feactures= \n",
      " [[  0.           0.1         66.        ]\n",
      " [ -0.24489796   0.1         66.        ]\n",
      " [ -0.48979592   0.1         66.        ]\n",
      " ...\n",
      " [-11.51020408   0.5         80.        ]\n",
      " [-11.75510204   0.5         80.        ]\n",
      " [-12.           0.5         80.        ]]\n",
      "\n",
      "\n",
      "labels= \n",
      " [[9.47515373e-02 0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
      " [1.83608702e-01 1.41110961e-04 9.01997379e-01 1.62358493e-10]\n",
      " [3.22333902e-01 4.33937896e-04 7.48914062e-01 4.77144941e-10]\n",
      " ...\n",
      " [4.20164900e-02 9.58104047e-01 5.58399792e-11 3.78984027e-01]\n",
      " [3.19464665e-02 9.68145182e-01 5.73926563e-11 6.15280156e-01]\n",
      " [2.39153274e-02 9.76153281e-01 5.75109456e-11 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Now, here are the datasets\n",
    "print('feactures= \\n',X0)\n",
    "print('\\n')\n",
    "print('labels= \\n',Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos los datos en validación y entrenamiento\n",
    "X_learn, Y_learn, X_val, Y_val = split(X0, Y2, 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0,\n",
    "                                   patience=100,\n",
    "                                   restore_best_weights=True, verbose=False)\n",
    "                                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, X_train, Y_train, X_test, Y_test):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(int(X_train.shape[1])))\n",
    "    \n",
    "    for i in range(hparams['HP_LAYERS']):        \n",
    "        model.add(Dense(hparams['HP_NUM_UNITS'], activation='relu'))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "     \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hparams['HP_LEARNING'], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse', \n",
    "            metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    train = model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=hparams['HP_BATCHSIZE'], shuffle=False, verbose=False)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return model, loss, train.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid\n",
    "\n",
    "- layers 4 \t\n",
    "- nodes 200 \t\n",
    "- lr 0.00010 \t\n",
    "- bs 8 \t\n",
    "\n",
    "loss = 0.000008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_grid = {'HP_LAYERS': 4, 'HP_NUM_UNITS': 200, 'HP_BATCHSIZE': 8, 'HP_LEARNING':0.0001}\n",
    "model_grid, loss_grid, history_grid = train_test_model(hparams_grid, X_learn, Y_learn, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_grid['loss'], label='Training')\n",
    "plt.plot(history_grid['val_loss'], label='Validation')\n",
    "plt.ylabel('Loss function')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic\n",
    "\n",
    "- layers 3\n",
    "- number of neurons: 100\n",
    "- Batch size 4\n",
    "- Learning rate: 0.0001\n",
    "\n",
    "loss = 0.029919\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_gen = {'HP_LAYERS': 3, 'HP_NUM_UNITS': 100, 'HP_BATCHSIZE': 4, 'HP_LEARNING':0.0001}\n",
    "model_gen, loss_gen, history_gen = train_test_model(hparams_gen, X_learn, Y_learn, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_gen['loss'], label='Training')\n",
    "plt.plot(history_gen['val_loss'], label='Validation')\n",
    "plt.ylabel('Loss function')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=np.linspace(0,-12,50)\n",
    "dom=[]\n",
    "dom2=[]\n",
    "dom3=[]\n",
    "#different combinations for the params\n",
    "\n",
    "for z in Z: dom.append([z,0.5,80]) \n",
    "A=model.predict(dom)               \n",
    "# ¡¡¡ The inverse transformation must be applied in order to return the labels to their original ranges!!!\n",
    "A=scaler.inverse_transform(A) \n",
    "\n",
    "for z in Z: dom2.append([z,0.3,70]) \n",
    "B_grid=model_grid.predict(dom2)\n",
    "B_grid=scaler.inverse_transform(B_grid)\n",
    "\n",
    "B_gen=model_grid.predict(dom2)\n",
    "B_gen=scaler.inverse_transform(B_gen)\n",
    "\n",
    "for z in Z: dom3.append([z,0.4,67]) \n",
    "C=model.predict(dom3)\n",
    "C=scaler.inverse_transform(C)\n",
    "#función real\n",
    "D=EDO(Z, 0.3,70)\n",
    "\n",
    "\n",
    "\n",
    "#Realvs model\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Z,B_grid[:,0],color='darkblue')\n",
    "plt.plot(Z,B_grid[:,1],color='darkblue')\n",
    "plt.plot(Z,B_grid[:,2],color='darkblue', label='Grid')\n",
    "#plt.plot(Z,B[:,3])\n",
    "\n",
    "plt.plot(Z,B_gen[:,0],color='darkblue')\n",
    "plt.plot(Z,B_gen[:,1],color='darkblue')\n",
    "plt.plot(Z,B_gen[:,2],color='darkblue', label='Genetic')\n",
    "#plt.plot(Z,B[:,3])\n",
    "\n",
    "plt.plot(Z,D[:,0],color='darkred')\n",
    "plt.plot(Z,D[:,1],color='darkred')\n",
    "plt.plot(Z,D[:,2],color='darkred', label='$\\Omega_i$ real solutions')\n",
    "#plt.plot(Z,D[:,3])\n",
    "\n",
    "#plt.title()\n",
    "plt.xlabel('$\\ln(a)$', size=15, color='darkblue')\n",
    "plt.ylabel('$\\Omega_i$', size=15, color='darkblue')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "plt.annotate('$\\Omega_m$', xy=(-2,1), xytext=(-4,0.8), size=15,\n",
    "           arrowprops=dict(arrowstyle='-|>', connectionstyle=\"angle3,angleA=0,angleB=-90\"))\n",
    "\n",
    "plt.annotate('$\\Omega_r$', xy=(-10,0.89), xytext=(-11,0.7),size=15,\n",
    "           arrowprops=dict(arrowstyle='-|>'))\n",
    "\n",
    "plt.annotate('$\\Omega_{\\Lambda}$', xy=(-6,0), xytext=(-8.5,0.1),size=15,\n",
    "           arrowprops=dict(arrowstyle='-|>', connectionstyle=\"angle3,angleA=0,angleB=90\"))\n",
    "\n",
    "#plt.savefig('red_vs_sol.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
