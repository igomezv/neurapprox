{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from keras import activations\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "from elitism import eaSimpleWithElitism, main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos: SDSS DR17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      delta         u         g         r         i         z  \\\n",
       "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
       "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
       "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
       "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
       "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
       "\n",
       "   redshift   class  \n",
       "0  0.634794  GALAXY  \n",
       "1  0.779136  GALAXY  \n",
       "2  0.644195  GALAXY  \n",
       "3  0.932346  GALAXY  \n",
       "4  0.116123  GALAXY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./SDSS/star_classification.csv')\n",
    "cols = ['alpha','delta','u','g','r','i','z','redshift','class']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambian las clases a vectores con números enteros\n",
    "\n",
    "$$ \\text{GALAXY}: \\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\\quad \\text{STAR}: \\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix},\\quad \\text{QSO}:\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   redshift  class  \n",
      "0  0.634794      0  \n",
      "1  0.779136      0  \n",
      "2  0.644195      0  \n",
      "3  0.932346      0  \n",
      "4  0.116123      0  \n"
     ]
    }
   ],
   "source": [
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n",
    "\n",
    "Se establecen las funciones necesarias para aplicar el algorítmo genético a partir de lo siguiente\n",
    "\n",
    "- 1) Decodificar el gen del individuo para obtener el núm. de capas ocultas, núm. de neuronas y la tasa de aprendizaje.\n",
    "    \n",
    "    \n",
    "- 2) Preparar el conjunto de datos para dividirlos en conjunto de entrenamiento y validación.\n",
    "    \n",
    "    \n",
    "- 3) Entrenar la red neuronal, calcular la presición del modelo en el conjunto de validación y regresarlo como fitness score para el algorítmo genético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function layers\n",
    "\n",
    "f1 = lambda x: Dense(x, activation='relu')      #ReLU\n",
    "f2 = lambda x: keras.layers.LeakyReLU(0.3)      #LReLU\n",
    "f3 = lambda x: Dense(x, activation='elu')       #ELU\n",
    "f4 = lambda x: Dense(x, kernel_initializer='lecun_normal', activation='selu')   #SELU\n",
    "\n",
    "f_names = [\"ReLU\", \"LReLU\", \"ELU\", \"SELU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_DEEP       = np.array([2,4,8,16,24,32,48,64])        # Number of deep layers (8)\n",
    "SC_NUM_UNITS  = np.array([8,16,24,32,40,48,56,64])   # Number of fully conected neurons (8)\n",
    "SC_LEARNING   = np.array([1e-4,1e-3,1e-2,1e-1])         # Learning rates (4)\n",
    "SC_ACTIVATION = [f1, f2, f3, f4]                        # Activation function layers (4)\n",
    "# SC_BATCHSIZE = np.array([16,32])\n",
    "\n",
    "# callbacks = [keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max',\n",
    "#                                min_delta=0,\n",
    "#                                patience=6,\n",
    "#                                restore_best_weights=True)]\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto',\n",
    "                               min_delta=0.01, \n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               baseline=0.98, restore_best_weights=False)]\n",
    "    \n",
    "batch_size = 128;      epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into X and Y and implement hot_ones in Y\n",
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:8]\n",
    "    Y = data[:,8]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and validation (70/30)\n",
    "X,Y = prepare_dataset(data)\n",
    "X_train, X_test, Y_train, Y_test = split(X, Y, test_size = 0.3, random_state = 0)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss= [2,2,2,2]\n",
    "sss.pop()\n",
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    t = time.time(); t_total = 0\n",
    "    \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_layers_bits   = BitArray(ga_individual_solution[0:3])   # (8)\n",
    "    num_units_bits     = BitArray(ga_individual_solution[3:6])   # (8)\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[6:8])   # (4)\n",
    "    activation_f_bits  = BitArray(ga_individual_solution[8:10])  # (4)\n",
    "    \n",
    "    deep_layers   = SC_DEEP[deep_layers_bits.uint]\n",
    "    num_units     = SC_NUM_UNITS[num_units_bits.uint]\n",
    "    learning_rate = SC_LEARNING[learning_rate_bits.uint]\n",
    "    activation_f  = SC_ACTIVATION[activation_f_bits.uint]\n",
    "    \n",
    "    print('\\n--------------- Starting trial:', len(ss), \"---------------\")\n",
    "    print('Deep Layers: ',deep_layers,', Number of neurons: ',num_units,\", Learning rate: \",learning_rate,', Activation function: ',f_names[activation_f_bits.uint])\n",
    "#     print(\"-------------------------------------------------\")\n",
    "    \n",
    "    # Train model and predict on validation set\n",
    "    model = keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(num_units, input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(deep_layers):        \n",
    "        model.add(activation_f(num_units))\n",
    "        if i % SC_NUM_UNITS[1]==0:\n",
    "            model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=batch_size, shuffle=True, verbose=0)\n",
    "    \n",
    "    _, score = model.evaluate(X_test, Y_test)    \n",
    "    t = time.time()-t; ss = ss[1:]\n",
    "    print(\"Accuracy:\", score, \", Elapsed time:\", t)\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "\n",
    "#     datos.append([deep_layers, num_units, learning_rate, f_names[activation_f_bits.uint], score, t])\n",
    "    \n",
    "    return score,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, use la paquetería DEAP para definir las cosas para ejecutar GA. Usaremos una representación binaria para la solución de longitud diez. Se inicializará aleatoriamente utilizando la distribución de Bernoulli. Del mismo modo, se utiliza el crossover ordenado, la mutación aleatoria y la selección de la rueda de la ruleta. Los valores del parámetro GA se inicializan arbitrariamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ad8dfa3051b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mbest_population\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total elapsed time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"minutes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-ad8dfa3051b5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# perform the Genetic Algorithm flow with elitism:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n\u001b[1;32m---> 52\u001b[1;33m                                               ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# print info for best solution found:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Zona-de-pruebas\\neurapprox\\elitism.py\u001b[0m in \u001b[0;36meaSimpleWithElitism\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-da0d1ab4aec0>\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[1;34m(ga_individual_solution)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mactivation_f\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mSC_ACTIVATION\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactivation_f_bits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n--------------- Starting trial:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"---------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Deep Layers: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeep_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m', Number of neurons: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\", Learning rate: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m', Activation function: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactivation_f_bits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     print(\"-------------------------------------------------\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'ss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "population_size = 40; \n",
    "max_generations = 20\n",
    "gene_length = 10;\n",
    "k = 5\n",
    "\n",
    "# Genetic Algorithm constants:\n",
    "P_CROSSOVER = 0.85  # probability for crossover\n",
    "P_MUTATION = 0.5   # (try also 0.5) probability for mutating an individual\n",
    "HALL_OF_FAME_SIZE = 1\n",
    "CROWDING_FACTOR = 25.0  # crowding factor for crossover and mutation\n",
    "\n",
    "# datos = []\n",
    "ss = [i for i in range(1,population_size*max_generations + 1)]\n",
    "\n",
    "# set the random seed:\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMax', base.Fitness, weights = [1.0])\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "# create the individual operator to fill up an Individual instance:\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "\n",
    "# create the population operator to generate a list of individuals:\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "# genetic operators:\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "# Genetic Algorithm flow:\n",
    "def main():\n",
    "\n",
    "    # create initial population (generation 0):\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    # prepare the statistics object:\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "\n",
    "    # define the hall-of-fame object:\n",
    "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
    "\n",
    "    # perform the Genetic Algorithm flow with elitism:\n",
    "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
    "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # print info for best solution found:\n",
    "    best = hof.items[0]\n",
    "    print(\"-- Best Individual = \", best)\n",
    "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
    "\n",
    "    # extract statistics:\n",
    "    maxFitnessValues, meanFitnessValues = logbook.select(\"max\", \"avg\")\n",
    "\n",
    "    # plot statistics:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
    "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
    "    plt.xlabel('Generation'); plt.ylabel('max / Average Fitness')\n",
    "    plt.legend()\n",
    "    plt.title('Max and Average fitness over Generations')\n",
    "#     plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    \n",
    "    best_population = tools.selBest(population,k = k)\n",
    "    return best_population\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = time.time()\n",
    "    best_population = main()\n",
    "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_deep_layers   = []\n",
    "Best_num_units     = []\n",
    "Best_learning_rate = []\n",
    "Best_activation_f  = []\n",
    "\n",
    "t = 0\n",
    "\n",
    "for bi in best_individuals:\n",
    "    deep_layers_bits   = BitArray(bi[0:3])\n",
    "    num_units_bits     = BitArray(bi[3:6])\n",
    "    learning_rate_bits = BitArray(bi[6:8])\n",
    "    activation_f_bits  = BitArray(bi[8:10])\n",
    "    t += 1 \n",
    "    \n",
    "    Best_deep_layers.append(  SC_DEEP[deep_layers_bits.uint])\n",
    "    Best_num_units.append(    SC_NUM_UNITS[num_units_bits.uint])\n",
    "    Best_learning_rate.append(SC_LEARNING[learning_rate_bits.uint])\n",
    "    Best_activation_f.append( SC_ACTIVATION[activation_f_bits.uint])\n",
    "    print('k=',t,'\\nDeep Layers: ', Best_deep_layers[-1], ', Num of Units: ', Best_num_units[-1], ', Learning rate: ', Best_learning_rate[-1], \", Activation function: \", Best_activation_f[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_sdss.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Activation function\", \"Accuracy\", \"Elapsed time\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Elapsed time\"], ascending=[0,0], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df[[\"Tiempo de ejecución\"]])/60/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = os.path.join('.\\\\', filename)\n",
    "while True:\n",
    "    try: \n",
    "        df \n",
    "        break\n",
    "    except:\n",
    "        df = pd.read_csv(pathname, delimiter = \"\\t\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona los mejores k individuos - (para k=5)\n",
    "k = 10\n",
    "best_genes = df.iloc[:k,]\n",
    "\n",
    "best_deep_size = best_genes.iloc[:,0]\n",
    "best_num_units = best_genes.iloc[:,1]\n",
    "best_learning_rate = best_genes.iloc[:,2]\n",
    "\n",
    "best_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_deep_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model using best configuration on complete training set \n",
    "#and make predictions on the test set\n",
    "\n",
    "X,Y = prepare_dataset(data)\n",
    "X_train, X_test, Y_train, Y_test = split(X, Y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "models = []\n",
    "historial = []\n",
    "y_pred = []\n",
    "\n",
    "for k in range(len(best_deep_size)):\n",
    "    print('\\n--- Starting trial:', k)\n",
    "    print('Deep Size: ', best_deep_size[k], ', Num of Units: ', best_num_units[k], ', Learning rate: ', best_learning_rate[k])\n",
    "    \n",
    "    models.append(keras.Sequential())\n",
    "    models[-1].add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    models[-1].add(Dense(best_num_units[k], input_shape=(int(X_train.shape[1]),)))\n",
    "#     x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "\n",
    "    for i in range(best_deep_size[k]):        \n",
    "        models[-1].add(Dense(best_num_units[k], activation='relu'))\n",
    "    models[-1].add(Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=best_learning_rate[k], beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    models[-1].compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=CategoricalCrossentropy(),\n",
    "            metrics=[\"categorical_accuracy\"])\n",
    "            \n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode='max',\n",
    "                                       min_delta=0,\n",
    "                                       patience=50,\n",
    "                                       restore_best_weights=True)]\n",
    "#     history = models[-1].fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "#                         epochs=best_epochs, callbacks=callbacks, batch_size=best_batch_size, shuffle=True)\n",
    "    historial.append(models[-1].fit(X_train, y_train, epochs=20, validation_data=(X_test, Y_test),\n",
    "                                    batch_size=128, shuffle=True))\n",
    "    y_pred.append(models[-1].predict(X))\n",
    "    \n",
    "    _, score = models[-1].evaluate(X_test, Y_test)  \n",
    "\n",
    "    print('Test score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(14,6), sharey='row')\n",
    "fig.suptitle('Best models')\n",
    "titles = []\n",
    "for k in range(len(models)):\n",
    "    titles.append(f\"Model loss {k+1} (log)\")\n",
    "    axs[k].plot(historial[k].history['loss'])\n",
    "    axs[k].plot(historial[k].history['val_loss'])\n",
    "#     print(titles[-1])\n",
    "    axs[k].set_title(titles[-1])\n",
    "    axs[k].set_yscale(\"log\")\n",
    "    axs[k].legend(['train', 'test'], loc='upper left')\n",
    "    axs[k].grid()\n",
    "\n",
    "for ax in axs.flat:\n",
    "#     ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "    ax.set(xlabel='Epoch')\n",
    "axs.flat[0].set(ylabel='Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficas de comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1 = np.argmax(models[0].predict(X), axis=1)\n",
    "Y_pred2 = np.argmax(models[1].predict(X), axis=1)\n",
    "# Y_pred3 = np.argmax(models[2].predict(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[:,4].min(),X[:,4].max(), X[:,4].mean(), X[:,4].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(X[:,2], X[:,3], X[:,4], marker='+', c=np.argmax(Y,axis=1), cmap='brg', alpha=1)\n",
    "ax.set_xlabel('$u$', fontsize=15); ax.set_xlim([10, 30])\n",
    "ax.set_ylabel('$g$', fontsize=15); ax.set_ylim([5, 35])\n",
    "ax.set_zlabel('$r$', fontsize=15); ax.set_zlim([8, 25])\n",
    "plt.colorbar(p, shrink=0.5, label='Etiqueta objeto'); plt.title(r\"Clasificación de objetos estelares (Datos originales)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(X[:,2], X[:,3], X[:,4], marker='+', c=Y_pred1, cmap='brg', alpha=1)\n",
    "ax.set_xlabel('$u$', fontsize=15); ax.set_xlim([10, 30])\n",
    "ax.set_ylabel('$g$', fontsize=15); ax.set_ylim([5, 35])\n",
    "ax.set_zlabel('$r$', fontsize=15); ax.set_zlim([8, 25])\n",
    "plt.colorbar(p, shrink=0.5, label='Etiqueta objeto'); plt.title(r\"Clasificación de objetos estelares (Modelo 1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(X[:,2], X[:,3], X[:,4], marker='+', c=Y_pred2, cmap='brg', alpha=1)\n",
    "ax.set_xlabel('$u$', fontsize=15); ax.set_xlim([10, 30])\n",
    "ax.set_ylabel('$g$', fontsize=15); ax.set_ylim([5, 35])\n",
    "ax.set_zlabel('$r$', fontsize=15); ax.set_zlim([8, 25])\n",
    "plt.colorbar(p, shrink=0.5, label='Etiqueta objeto'); plt.title(r\"Clasificación de objetos estelares (Modelo 2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_genes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1= sns.jointplot(data=df, x=\"Deep size\", y=\"Num units\", kind=\"kde\")\n",
    "g1.ax_joint.scatter(best_genes.iloc[:,0], best_genes.iloc[:,1], color = 'red', label=\"a\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "g2= sns.jointplot(x=df.iloc[:,2], y=df.iloc[:,4], kind='kde')\n",
    "g2.ax_joint.scatter(best_genes.iloc[:,2], best_genes.iloc[:,4], color = 'red', label=\"a\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "# fig.suptitle('Última generación de hipermarámetros obtenidos')\n",
    "\n",
    "# # axs[0].plot(df.iloc[:,0], df.iloc[:,1], alpha=0.5, c='blue', label=\"Model pred 1\")\n",
    "# axs[0].scatter(df.iloc[:,0], df.iloc[:,1], s=20, alpha=0.3, c='red', label=\"Model pred 1\")\n",
    "# axs[0].scatter(best_genes.iloc[:,0], best_genes.iloc[:,1], s=80, alpha=1, c='red', label=\"Mejores individuos\")\n",
    "# axs[0].grid(); axs[0].legend()\n",
    "# # axs[0].legend(loc='upper right'); \n",
    "# # axs[0].set_xlim([2, 18]); axs[0].set_ylim([1, 65])\n",
    "# axs[0].set(xlabel=r'Deep size', ylabel='Num units')\n",
    "\n",
    "# # axs[1].plot(df.iloc[:,2], df.iloc[:,3], alpha=0.5, c='blue', label=\"Model pred 1\")\n",
    "# axs[1].scatter(df.iloc[:,2], df.iloc[:,3], s=20, alpha=0.3, c='red', label=\"Model pred 1\")\n",
    "# axs[1].scatter(best_genes.iloc[:,2], best_genes.iloc[:,3], s=80, alpha=1, c='red', label=\"Mejores individuos\")\n",
    "# axs[1].set_yscale(\"log\"); \n",
    "# axs[1].grid(); axs[1].legend(loc='upper right')\n",
    "# # axs[1].set_xlim([1e-4, 31e-4]); axs[1].set_ylim([2**1, 2**4])\n",
    "# axs[1].set(xlabel=r'Learning rate', ylabel='Batch size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
