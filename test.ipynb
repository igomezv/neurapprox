{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k         r         x  A[k,r,x]\n",
      "0  0.001  0.010817 -0.973907  1.009217\n",
      "1  0.001  0.010817 -0.679410  1.009143\n",
      "2  0.001  0.010817 -0.148874  1.009077\n",
      "3  0.001  0.010817  0.148874  1.009077\n",
      "4  0.001  0.010817  0.679410  1.009142\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/AT.dat', delimiter=\"\\t\",\n",
    "                   skiprows=[0], names=[\"k\",\"r\",\"x\",\"A[k,r,x]\"])\n",
    "print(data.head())\n",
    "data = data.to_numpy()\n",
    "\n",
    "# Use first 8,056 points as training/validation and rest as test set.\n",
    "train_data = data[0:8056]\n",
    "test_data = data[8056:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Now, we have a fair understanding of what GA is and how it works. Next, let’s get to coding.\n",
    "\n",
    "We will use wind power forecast data, which is available at the following link. It consists of normalized (between zero and one) wind power measurements from seven wind farms. To keep things simple, we will use first wind farm data (column named wp1) but I encourage the reader to experiment and extend the code to forecast energy for all seven, wind farms.\n",
    "\n",
    "Let’s import required packages, load the dataset and define two helper functions. The first method prepare_dataset will segment the data into chunks to create X, Y pair for model training. The X will the wind power values from the past (e.g. 1 to t-1) and Y will be future value at time t. The second method train_evaluate perform three things, 1) decoding GA solution to get window size and number of units. 2) Prepare the dataset using window size found by GA and divide into train and validation set, and 3) train LSTM model, calculate RMSE on validation set and return it as a fitness score of the current GA solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8556, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,1].shape\n",
    "data[:,0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(11)[6:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:,0:3]\n",
    "    Y = data[:,3]  \n",
    "    return X, Y\n",
    "\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    deep_size_bits = BitArray(ga_individual_solution[0:3])\n",
    "    num_units_bits = BitArray(ga_individual_solution[3:8])\n",
    "    learning_rate_bits = BitArray(ga_individual_solution[8:12])\n",
    "    batch_size_bits = BitArray(ga_individual_solution[12:14])\n",
    "    epochs_bits = BitArray(ga_individual_solution[14:])\n",
    "    \n",
    "    deep_size = deep_size_bits.uint +2\n",
    "    num_units = num_units_bits.uint +1\n",
    "    learning_rate = (learning_rate_bits.uint+1)*10**(-4)\n",
    "    batch_size = 2**(batch_size_bits.uint +1)\n",
    "    epochs = (epochs_bits.uint +1)*50\n",
    "    \n",
    "    print('\\nDeep Size: ', deep_size, ', Num of Units: ', num_units, ', Learning rate: ', learning_rate)\n",
    "    print('Batch Size: ', batch_size, \", Num of Epochs: \", epochs)\n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    X,Y = prepare_dataset(train_data)\n",
    "    X_train, X_test, y_train, y_test = split(X, Y, test_size = 0.20, random_state = 1120)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(3,)))\n",
    "    model.add(layers.Dense(num_units, input_shape=(3,)))\n",
    "#     x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "    \n",
    "    for i in range(deep_size):        \n",
    "        model.add(layers.Dense(num_units, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0,\n",
    "                                   patience=8,\n",
    "                                   restore_best_weights=True)]\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "              epochs=epochs, callbacks=callbacks, batch_size=batch_size, shuffle=True)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE score as fitness score for GA\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print('Validation RMSE: ', rmse,'\\n')\n",
    "    \n",
    "    return rmse,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, use la paquetería DEAP para definir las cosas para ejecutar GA. Usaremos una representación binaria para la solución de longitud diez. Se inicializará aleatoriamente utilizando la distribución de Bernoulli. Del mismo modo, se utiliza el crossover ordenado, la mutación aleatoria y la selección de la rueda de la ruleta. Los valores del parámetro GA se inicializan arbitrariamente; Te sugerimos que juegues con diferentes configuraciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshu\\.conda\\envs\\tensorflow\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\Joshu\\.conda\\envs\\tensorflow\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep Size:  5 , Num of Units:  12 , Learning rate:  0.0005\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 15s 2ms/sample - loss: 41.6328 - val_loss: 0.0924\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 8s 1ms/sample - loss: 83.7940 - val_loss: 0.1151\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.0848 - val_loss: 0.0450\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.0497 - val_loss: 0.1312\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 9.1879 - val_loss: 0.0121\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.0375 - val_loss: 0.0872\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 6.8655 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 1.7589 - val_loss: 0.1201\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.8685 - val_loss: 0.0040\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.0020 - val_loss: 7.5744e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.4913 - val_loss: 0.0330\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.0526 - val_loss: 0.0067\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 1.0667 - val_loss: 0.2439\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 2.5695 - val_loss: 9.1992e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0012 - val_loss: 4.4568e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0979 - val_loss: 0.2229\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 8s 1ms/sample - loss: 0.0824 - val_loss: 9.0942e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.1086 - val_loss: 0.0021\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.3675 - val_loss: 9.9300e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0482 - val_loss: 0.0029\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0051 - val_loss: 6.1849e-04\n",
      "Epoch 23/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0024 - val_loss: 4.9089e-04\n",
      "Validation RMSE:  0.0211111343131454 \n",
      "\n",
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 13s 2ms/sample - loss: 2.3953 - val_loss: 0.0195\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0160 - val_loss: 9.9983e-04\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 6.2445e-04 - val_loss: 5.1276e-04\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 4.6019e-04 - val_loss: 3.9662e-04\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 8.0353e-04 - val_loss: 4.6169e-04\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 8s 1ms/sample - loss: 4.1554e-04 - val_loss: 3.5983e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 3.7669e-04 - val_loss: 3.4733e-04\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.3196e-04 - val_loss: 3.4869e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 3.7335e-04 - val_loss: 3.2226e-04\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 3.4272e-04 - val_loss: 3.8967e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.8796e-04 - val_loss: 4.6395e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 0.0012 - val_loss: 5.3282e-04\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.4572 - val_loss: 6.0323e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.2838e-04 - val_loss: 3.4882e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.2363e-04 - val_loss: 2.6966e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 3.0591e-04 - val_loss: 2.4812e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.3022e-04 - val_loss: 4.3380e-04\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 8s 1ms/sample - loss: 4.5021e-04 - val_loss: 5.6380e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 3.6597e-04 - val_loss: 3.3301e-04\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 4.3927e-04 - val_loss: 3.6093e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.9323e-04 - val_loss: 2.9288e-04\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 2.9296e-04 - val_loss: 2.8464e-04\n",
      "Epoch 23/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 7.5161e-04 - val_loss: 4.7705e-04\n",
      "Epoch 24/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 4.3774e-04 - val_loss: 5.3524e-04\n",
      "Validation RMSE:  0.0157516857671742 \n",
      "\n",
      "\n",
      "Deep Size:  7 , Num of Units:  18 , Learning rate:  0.0006000000000000001\n",
      "Batch Size:  16 , Num of Epochs:  50\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 8.7162 - val_loss: 0.3223\n",
      "Epoch 2/50\n",
      "6444/6444 [==============================] - 3s 458us/sample - loss: 0.1908 - val_loss: 0.0733\n",
      "Epoch 3/50\n",
      "6444/6444 [==============================] - 3s 476us/sample - loss: 0.0622 - val_loss: 0.0500\n",
      "Epoch 4/50\n",
      "6444/6444 [==============================] - 3s 499us/sample - loss: 0.0530 - val_loss: 0.0665\n",
      "Epoch 5/50\n",
      "6444/6444 [==============================] - 3s 480us/sample - loss: 0.0570 - val_loss: 0.0565\n",
      "Epoch 6/50\n",
      "6444/6444 [==============================] - 3s 513us/sample - loss: 0.0598 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "6444/6444 [==============================] - 3s 510us/sample - loss: 0.0218 - val_loss: 0.1712\n",
      "Epoch 8/50\n",
      "6444/6444 [==============================] - 3s 486us/sample - loss: 10.2345 - val_loss: 6.7817\n",
      "Epoch 9/50\n",
      "6444/6444 [==============================] - 3s 484us/sample - loss: 0.1800 - val_loss: 0.0249\n",
      "Epoch 10/50\n",
      "6444/6444 [==============================] - 3s 485us/sample - loss: 0.0190 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "6444/6444 [==============================] - 4s 569us/sample - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      "6444/6444 [==============================] - 3s 437us/sample - loss: 0.0020 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "6444/6444 [==============================] - 4s 562us/sample - loss: 0.0014 - val_loss: 7.0243e-04\n",
      "Epoch 14/50\n",
      "6444/6444 [==============================] - 4s 608us/sample - loss: 5.9904e-04 - val_loss: 5.7086e-04\n",
      "Epoch 15/50\n",
      "6444/6444 [==============================] - 3s 479us/sample - loss: 4.7766e-04 - val_loss: 4.6305e-04\n",
      "Epoch 16/50\n",
      "6444/6444 [==============================] - 3s 500us/sample - loss: 5.0385e-04 - val_loss: 7.5852e-04\n",
      "Epoch 17/50\n",
      "6444/6444 [==============================] - 3s 499us/sample - loss: 8.8826e-04 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "6444/6444 [==============================] - 3s 509us/sample - loss: 0.0115 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "6444/6444 [==============================] - 3s 448us/sample - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "6444/6444 [==============================] - 3s 519us/sample - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 21/50\n",
      "6444/6444 [==============================] - 4s 593us/sample - loss: 0.0013 - val_loss: 5.2499e-04\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6444/6444 [==============================] - 3s 535us/sample - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "6444/6444 [==============================] - 3s 485us/sample - loss: 0.0035 - val_loss: 8.3438e-04\n",
      "Validation RMSE:  0.021518602742485935 \n",
      "\n",
      "\n",
      "Deep Size:  7 , Num of Units:  22 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  8 , Num of Epochs:  50\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/50\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 37.2968 - val_loss: 0.1885\n",
      "Epoch 2/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 7.7595 - val_loss: 0.0391\n",
      "Epoch 3/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0230 - val_loss: 0.0114\n",
      "Epoch 4/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0133 - val_loss: 0.0057\n",
      "Epoch 5/50\n",
      "6444/6444 [==============================] - 6s 977us/sample - loss: 0.0141 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      "6444/6444 [==============================] - 6s 876us/sample - loss: 0.0081 - val_loss: 0.0182\n",
      "Epoch 7/50\n",
      "6444/6444 [==============================] - 6s 861us/sample - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0090 - val_loss: 0.0014\n",
      "Epoch 9/50\n",
      "6444/6444 [==============================] - 6s 979us/sample - loss: 0.0078 - val_loss: 3.5661e-04\n",
      "Epoch 10/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0198 - val_loss: 6.8808e-04\n",
      "Epoch 11/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 1.4626 - val_loss: 7.1128e-04\n",
      "Epoch 12/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0012 - val_loss: 3.9240e-04\n",
      "Epoch 14/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 3.8070e-04 - val_loss: 3.4435e-04\n",
      "Epoch 15/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 3.4713e-04 - val_loss: 3.3347e-04\n",
      "Epoch 16/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 3.1907e-04 - val_loss: 2.9835e-04\n",
      "Epoch 17/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.1127 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "6444/6444 [==============================] - 5s 827us/sample - loss: 0.0010 - val_loss: 4.9952e-04\n",
      "Epoch 19/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 7.9588e-04 - val_loss: 4.3461e-04\n",
      "Epoch 20/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 4.4099e-04 - val_loss: 4.2333e-04\n",
      "Epoch 21/50\n",
      "6444/6444 [==============================] - 6s 941us/sample - loss: 4.6945e-04 - val_loss: 6.4421e-04\n",
      "Epoch 22/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 0.0011 - val_loss: 3.1729e-04\n",
      "Epoch 23/50\n",
      "6444/6444 [==============================] - 6s 974us/sample - loss: 4.4556e-04 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "6444/6444 [==============================] - 5s 848us/sample - loss: 3.9936e-04 - val_loss: 2.8362e-04\n",
      "Epoch 25/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 2.8790e-04 - val_loss: 3.4862e-04\n",
      "Epoch 26/50\n",
      "6444/6444 [==============================] - 6s 865us/sample - loss: 3.0096e-04 - val_loss: 2.5493e-04\n",
      "Epoch 27/50\n",
      "6444/6444 [==============================] - 5s 711us/sample - loss: 0.0021 - val_loss: 5.8465e-04\n",
      "Epoch 28/50\n",
      "6444/6444 [==============================] - 6s 906us/sample - loss: 4.0104e-04 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "6444/6444 [==============================] - 6s 908us/sample - loss: 0.0432 - val_loss: 3.9485e-04\n",
      "Epoch 30/50\n",
      "6444/6444 [==============================] - 6s 912us/sample - loss: 4.5149e-04 - val_loss: 2.9956e-04\n",
      "Epoch 31/50\n",
      "6444/6444 [==============================] - 6s 913us/sample - loss: 2.9977e-04 - val_loss: 2.4737e-04\n",
      "Epoch 32/50\n",
      "6444/6444 [==============================] - 6s 910us/sample - loss: 2.5483e-04 - val_loss: 2.4341e-04\n",
      "Epoch 33/50\n",
      "6444/6444 [==============================] - 6s 909us/sample - loss: 3.9840e-04 - val_loss: 2.5901e-04\n",
      "Epoch 34/50\n",
      "6444/6444 [==============================] - 6s 900us/sample - loss: 2.8817e-04 - val_loss: 2.4089e-04\n",
      "Epoch 35/50\n",
      "6444/6444 [==============================] - 6s 932us/sample - loss: 7.6582e-04 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "6444/6444 [==============================] - 6s 920us/sample - loss: 6.1634e-04 - val_loss: 2.5665e-04\n",
      "Epoch 37/50\n",
      "6444/6444 [==============================] - 6s 913us/sample - loss: 2.6318e-04 - val_loss: 2.8327e-04\n",
      "Epoch 38/50\n",
      "6444/6444 [==============================] - 6s 920us/sample - loss: 2.3507e-04 - val_loss: 2.4126e-04\n",
      "Epoch 39/50\n",
      "6444/6444 [==============================] - 6s 914us/sample - loss: 7.8644e-04 - val_loss: 3.3774e-04\n",
      "Epoch 40/50\n",
      "6444/6444 [==============================] - 6s 910us/sample - loss: 2.4439e-04 - val_loss: 2.4423e-04\n",
      "Epoch 41/50\n",
      "6444/6444 [==============================] - 6s 917us/sample - loss: 2.8306e-04 - val_loss: 2.4817e-04\n",
      "Epoch 42/50\n",
      "6444/6444 [==============================] - 6s 915us/sample - loss: 2.3493e-04 - val_loss: 2.1697e-04\n",
      "Epoch 43/50\n",
      "6444/6444 [==============================] - 6s 928us/sample - loss: 2.1709e-04 - val_loss: 1.9413e-04\n",
      "Epoch 44/50\n",
      "6444/6444 [==============================] - 6s 916us/sample - loss: 2.1493e-04 - val_loss: 3.2205e-04\n",
      "Epoch 45/50\n",
      "6444/6444 [==============================] - 6s 920us/sample - loss: 2.0657e-04 - val_loss: 2.0713e-04\n",
      "Epoch 46/50\n",
      "6444/6444 [==============================] - 6s 914us/sample - loss: 0.0027 - val_loss: 2.5133e-04\n",
      "Epoch 47/50\n",
      "6444/6444 [==============================] - 6s 909us/sample - loss: 2.5955e-04 - val_loss: 2.3875e-04\n",
      "Epoch 48/50\n",
      "6444/6444 [==============================] - 6s 938us/sample - loss: 2.4780e-04 - val_loss: 2.9949e-04\n",
      "Epoch 49/50\n",
      "6444/6444 [==============================] - 6s 906us/sample - loss: 2.6733e-04 - val_loss: 2.4819e-04\n",
      "Epoch 50/50\n",
      "6444/6444 [==============================] - 6s 912us/sample - loss: 2.4810e-04 - val_loss: 2.3314e-04\n",
      "Validation RMSE:  0.015268848493921718 \n",
      "\n",
      "\n",
      "Deep Size:  5 , Num of Units:  14 , Learning rate:  0.0006000000000000001\n",
      "Batch Size:  8 , Num of Epochs:  50\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/50\n",
      "6444/6444 [==============================] - 7s 1ms/sample - loss: 28.2179 - val_loss: 28.5646\n",
      "Epoch 2/50\n",
      "6444/6444 [==============================] - 5s 809us/sample - loss: 11.9392 - val_loss: 0.0845\n",
      "Epoch 3/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 0.0613 - val_loss: 0.0415\n",
      "Epoch 4/50\n",
      "6444/6444 [==============================] - 5s 819us/sample - loss: 0.0255 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "6444/6444 [==============================] - 5s 752us/sample - loss: 0.0593 - val_loss: 0.0401\n",
      "Epoch 6/50\n",
      "6444/6444 [==============================] - 5s 744us/sample - loss: 1.7304 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "6444/6444 [==============================] - 5s 809us/sample - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "6444/6444 [==============================] - 5s 816us/sample - loss: 0.0317 - val_loss: 0.4573\n",
      "Epoch 9/50\n",
      "6444/6444 [==============================] - 5s 768us/sample - loss: 0.1056 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "6444/6444 [==============================] - 6s 855us/sample - loss: 0.4743 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      "6444/6444 [==============================] - 6s 871us/sample - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "6444/6444 [==============================] - 6s 856us/sample - loss: 0.0134 - val_loss: 0.2110\n",
      "Epoch 13/50\n",
      "6444/6444 [==============================] - 5s 812us/sample - loss: 0.3498 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "6444/6444 [==============================] - 5s 811us/sample - loss: 0.1074 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "6444/6444 [==============================] - 5s 839us/sample - loss: 0.4540 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "6444/6444 [==============================] - 5s 825us/sample - loss: 0.0017 - val_loss: 7.5345e-04\n",
      "Epoch 17/50\n",
      "6444/6444 [==============================] - 5s 816us/sample - loss: 6.8689e-04 - val_loss: 5.8587e-04\n",
      "Epoch 18/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 6.1433e-04 - val_loss: 5.3484e-04\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6444/6444 [==============================] - 5s 804us/sample - loss: 5.8182e-04 - val_loss: 4.8999e-04\n",
      "Epoch 20/50\n",
      "6444/6444 [==============================] - 5s 819us/sample - loss: 5.4347e-04 - val_loss: 4.8618e-04\n",
      "Epoch 21/50\n",
      "6444/6444 [==============================] - 5s 813us/sample - loss: 5.4845e-04 - val_loss: 5.0401e-04\n",
      "Epoch 22/50\n",
      "6444/6444 [==============================] - 5s 809us/sample - loss: 5.4979e-04 - val_loss: 6.5162e-04\n",
      "Epoch 23/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 5.6484e-04 - val_loss: 5.3084e-04\n",
      "Epoch 24/50\n",
      "6444/6444 [==============================] - 5s 804us/sample - loss: 6.5651e-04 - val_loss: 6.2946e-04\n",
      "Epoch 25/50\n",
      "6444/6444 [==============================] - 5s 811us/sample - loss: 0.2038 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 0.0018 - val_loss: 5.9841e-04\n",
      "Epoch 27/50\n",
      "6444/6444 [==============================] - 5s 820us/sample - loss: 5.4497e-04 - val_loss: 4.9583e-04\n",
      "Epoch 28/50\n",
      "6444/6444 [==============================] - 5s 811us/sample - loss: 5.0399e-04 - val_loss: 4.4492e-04\n",
      "Epoch 29/50\n",
      "6444/6444 [==============================] - 5s 806us/sample - loss: 8.1960e-04 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "6444/6444 [==============================] - 5s 806us/sample - loss: 8.9599e-04 - val_loss: 5.5793e-04\n",
      "Epoch 31/50\n",
      "6444/6444 [==============================] - 5s 811us/sample - loss: 5.1778e-04 - val_loss: 4.4802e-04\n",
      "Epoch 32/50\n",
      "6444/6444 [==============================] - 5s 804us/sample - loss: 4.5777e-04 - val_loss: 4.8014e-04\n",
      "Epoch 33/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 4.3124e-04 - val_loss: 3.9713e-04\n",
      "Epoch 34/50\n",
      "6444/6444 [==============================] - 5s 808us/sample - loss: 4.2448e-04 - val_loss: 4.2070e-04\n",
      "Epoch 35/50\n",
      "6444/6444 [==============================] - 5s 826us/sample - loss: 4.0986e-04 - val_loss: 3.6828e-04\n",
      "Epoch 36/50\n",
      "6444/6444 [==============================] - 5s 802us/sample - loss: 3.9989e-04 - val_loss: 3.6324e-04\n",
      "Epoch 37/50\n",
      "6444/6444 [==============================] - 5s 809us/sample - loss: 3.9343e-04 - val_loss: 3.5470e-04\n",
      "Epoch 38/50\n",
      "6444/6444 [==============================] - 5s 825us/sample - loss: 3.8101e-04 - val_loss: 3.6921e-04\n",
      "Epoch 39/50\n",
      "6444/6444 [==============================] - 5s 804us/sample - loss: 4.0371e-04 - val_loss: 3.6522e-04\n",
      "Epoch 40/50\n",
      "6444/6444 [==============================] - 6s 873us/sample - loss: 3.7693e-04 - val_loss: 3.7242e-04\n",
      "Epoch 41/50\n",
      "6444/6444 [==============================] - 4s 593us/sample - loss: 3.7905e-04 - val_loss: 3.3730e-04\n",
      "Epoch 42/50\n",
      "6444/6444 [==============================] - 5s 801us/sample - loss: 3.6369e-04 - val_loss: 3.3523e-04\n",
      "Epoch 43/50\n",
      "6444/6444 [==============================] - 5s 819us/sample - loss: 4.5149e-04 - val_loss: 4.3838e-04\n",
      "Epoch 44/50\n",
      "6444/6444 [==============================] - 5s 837us/sample - loss: 3.9074e-04 - val_loss: 3.4377e-04\n",
      "Epoch 45/50\n",
      "6444/6444 [==============================] - 5s 806us/sample - loss: 3.7196e-04 - val_loss: 3.3805e-04\n",
      "Epoch 46/50\n",
      "6444/6444 [==============================] - 5s 805us/sample - loss: 3.5656e-04 - val_loss: 3.2316e-04\n",
      "Epoch 47/50\n",
      "6444/6444 [==============================] - 5s 806us/sample - loss: 7.7240e-04 - val_loss: 3.3543e-04\n",
      "Epoch 48/50\n",
      "6444/6444 [==============================] - 5s 835us/sample - loss: 3.3774e-04 - val_loss: 3.5217e-04\n",
      "Epoch 49/50\n",
      "6444/6444 [==============================] - 5s 803us/sample - loss: 3.2497e-04 - val_loss: 3.2429e-04\n",
      "Epoch 50/50\n",
      "6444/6444 [==============================] - 5s 804us/sample - loss: 3.0887e-04 - val_loss: 2.9488e-04\n",
      "Validation RMSE:  0.017171985459527254 \n",
      "\n",
      "gen\tnevals\n",
      "0  \t5     \n",
      "\n",
      "Deep Size:  5 , Num of Units:  12 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 16.1732 - val_loss: 0.0917\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.1533 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 1.1351 - val_loss: 0.0114\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 8.6595e-04 - val_loss: 5.9575e-04\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 6.4651e-04 - val_loss: 5.2083e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.2074 - val_loss: 8.7440e-04\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 7.2657e-04 - val_loss: 4.8211e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 5.0701e-04 - val_loss: 5.2603e-04\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.7074e-04 - val_loss: 6.1003e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.5076e-04 - val_loss: 4.0633e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.3776e-04 - val_loss: 4.2259e-04\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 4.3780e-04 - val_loss: 4.3818e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8699e-04 - val_loss: 3.9524e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8208e-04 - val_loss: 3.6145e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.6806e-04 - val_loss: 4.5187e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.4743e-04 - val_loss: 3.3319e-04\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.2077e-04 - val_loss: 5.4305e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8648e-04 - val_loss: 4.9692e-04\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.1027e-04 - val_loss: 2.6647e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9702e-04 - val_loss: 3.2335e-04\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.0061e-04 - val_loss: 2.7109e-04\n",
      "Epoch 23/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9798e-04 - val_loss: 2.8042e-04\n",
      "Epoch 24/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9298e-04 - val_loss: 2.8390e-04\n",
      "Epoch 25/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9233e-04 - val_loss: 2.7321e-04\n",
      "Epoch 26/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.0161e-04 - val_loss: 2.8332e-04\n",
      "Epoch 27/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.8732e-04 - val_loss: 2.9593e-04\n",
      "Epoch 28/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.8310e-04 - val_loss: 2.8008e-04\n",
      "Validation RMSE:  0.01632394167984406 \n",
      "\n",
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0005\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 0.4610 - val_loss: 0.0424\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.2946 - val_loss: 0.0162\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0177 - val_loss: 0.0020\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0124 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0744 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 0.0059 - val_loss: 6.7678e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0194 - val_loss: 8.0629e-04\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 0.0221 - val_loss: 9.2862e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0498 - val_loss: 6.5559e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 5.4880e-04 - val_loss: 4.7558e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.8155e-04 - val_loss: 4.4082e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0874 - val_loss: 0.0010\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 6.4395e-04 - val_loss: 6.3759e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.5117e-04 - val_loss: 3.8850e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0019 - val_loss: 9.9070e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 8.9624e-04 - val_loss: 5.0173e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 4.1184e-04 - val_loss: 3.3302e-04\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.2916e-04 - val_loss: 3.3637e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 3.1470e-04 - val_loss: 3.1010e-04\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.0450e-04 - val_loss: 2.9097e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 2.9899e-04 - val_loss: 2.9405e-04\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9598e-04 - val_loss: 2.8904e-04\n",
      "Epoch 23/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.9336e-04 - val_loss: 3.0927e-04\n",
      "Epoch 24/100\n",
      "6444/6444 [==============================] - 8s 1ms/sample - loss: 2.9218e-04 - val_loss: 2.9422e-04\n",
      "Epoch 25/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.9074e-04 - val_loss: 2.7864e-04\n",
      "Epoch 26/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.8190e-04 - val_loss: 2.8110e-04\n",
      "Epoch 27/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0016 - val_loss: 3.1948e-04\n",
      "Epoch 28/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.1483e-04 - val_loss: 3.2006e-04\n",
      "Epoch 29/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.8140e-04 - val_loss: 2.6850e-04\n",
      "Epoch 30/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.4728e-04 - val_loss: 2.3160e-04\n",
      "Epoch 31/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.2848e-04 - val_loss: 2.8049e-04\n",
      "Epoch 32/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.8536e-04 - val_loss: 2.6888e-04\n",
      "Epoch 33/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 2.7404e-04 - val_loss: 2.5077e-04\n",
      "Epoch 34/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.7642e-04 - val_loss: 2.7696e-04\n",
      "Epoch 35/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.6248e-04 - val_loss: 2.5243e-04\n",
      "Epoch 36/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.5410e-04 - val_loss: 2.6619e-04\n",
      "Epoch 37/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.4481e-04 - val_loss: 3.8057e-04\n",
      "Epoch 38/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 2.4575e-04 - val_loss: 2.3326e-04\n",
      "Validation RMSE:  0.015218398870598103 \n",
      "\n",
      "1  \t2     \n",
      "2  \t0     \n",
      "3  \t0     \n",
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 13s 2ms/sample - loss: 74.1307 - val_loss: 0.0492\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0239 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 8.3274e-04 - val_loss: 6.1876e-04\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 6.0537e-04 - val_loss: 4.9748e-04\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.0410e-04 - val_loss: 5.0880e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.9731e-04 - val_loss: 3.0993e-04\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.5706e-04 - val_loss: 2.5868e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 2.6684 - val_loss: 7.9329e-04\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.7448e-04 - val_loss: 4.1917e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.1746e-04 - val_loss: 4.0510e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8884e-04 - val_loss: 4.0128e-04\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8528e-04 - val_loss: 3.6320e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.4936e-04 - val_loss: 3.4556e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.3754e-04 - val_loss: 3.3034e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.3044e-04 - val_loss: 3.1075e-04\n",
      "Validation RMSE:  0.01608368399495612 \n",
      "\n",
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 12s 2ms/sample - loss: 39.9313 - val_loss: 0.0890\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 1.4020 - val_loss: 0.0274\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 7.9482 - val_loss: 0.0270\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.1467 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 9s 1ms/sample - loss: 0.0041 - val_loss: 9.8474e-04\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0056 - val_loss: 0.0010\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0275 - val_loss: 0.0085\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0089 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.2928 - val_loss: 0.0068\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0483 - val_loss: 0.3705\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0240 - val_loss: 0.0255\n",
      "Validation RMSE:  0.03138053219995062 \n",
      "\n",
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 1.3705 - val_loss: 0.1166\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0419 - val_loss: 0.0825\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0519 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0042 - val_loss: 9.9669e-04\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 9.2970 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 7.3364e-04 - val_loss: 5.5784e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.8192e-04 - val_loss: 6.8684e-04\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.2111e-04 - val_loss: 4.3032e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 0.0024 - val_loss: 3.7607e-04\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.2684e-04 - val_loss: 3.8757e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 10s 1ms/sample - loss: 5.5910e-04 - val_loss: 4.1605e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.3950e-04 - val_loss: 5.3771e-04\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 6.0208e-04 - val_loss: 3.0137e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.3752e-04 - val_loss: 2.9158e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.6993e-04 - val_loss: 3.4807e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 7.5127e-04 - val_loss: 5.5396e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.2820e-04 - val_loss: 4.2573e-04\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.1951e-04 - val_loss: 4.1125e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.6791e-04 - val_loss: 5.0478e-04\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 5.3911e-04 - val_loss: 5.3935e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 4.5061e-04 - val_loss: 3.3932e-04\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 10s 2ms/sample - loss: 3.8451e-04 - val_loss: 3.2939e-04\n",
      "Validation RMSE:  0.01707573900859959 \n",
      "\n",
      "\n",
      "Deep Size:  6 , Num of Units:  19 , Learning rate:  0.001\n",
      "Batch Size:  4 , Num of Epochs:  100\n",
      "Train on 6444 samples, validate on 1612 samples\n",
      "Epoch 1/100\n",
      "6444/6444 [==============================] - 13s 2ms/sample - loss: 4.9023 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.6862 - val_loss: 0.0974\n",
      "Epoch 3/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0379 - val_loss: 6.9978e-04\n",
      "Epoch 4/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0199 - val_loss: 0.0059\n",
      "Epoch 5/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.2936 - val_loss: 0.1429\n",
      "Epoch 6/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0989 - val_loss: 8.5163e-04\n",
      "Epoch 7/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0020 - val_loss: 0.0080\n",
      "Epoch 8/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 5.7463e-04 - val_loss: 4.6640e-04\n",
      "Epoch 9/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0196 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 0.0011 - val_loss: 5.3176e-04\n",
      "Epoch 11/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.7283e-04 - val_loss: 4.4783e-04\n",
      "Epoch 12/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 6.1852e-04 - val_loss: 4.7568e-04\n",
      "Epoch 13/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 5.1035e-04 - val_loss: 5.4946e-04\n",
      "Epoch 14/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 6.8019e-04 - val_loss: 5.5434e-04\n",
      "Epoch 15/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 5.1993e-04 - val_loss: 4.3401e-04\n",
      "Epoch 16/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.5415e-04 - val_loss: 3.7485e-04\n",
      "Epoch 17/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.8859e-04 - val_loss: 4.8331e-04\n",
      "Epoch 18/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 5.2138e-04 - val_loss: 4.4896e-04\n",
      "Epoch 19/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 5.6939e-04 - val_loss: 6.0644e-04\n",
      "Epoch 20/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.3330e-04 - val_loss: 3.4167e-04\n",
      "Epoch 21/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 7.2284e-04 - val_loss: 3.1642e-04\n",
      "Epoch 22/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.1343e-04 - val_loss: 2.6833e-04\n",
      "Epoch 23/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.0419e-04 - val_loss: 3.5630e-04\n",
      "Epoch 24/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.9870e-04 - val_loss: 2.5451e-04\n",
      "Epoch 25/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.6857e-04 - val_loss: 3.1430e-04\n",
      "Epoch 26/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.2353e-04 - val_loss: 2.9424e-04\n",
      "Epoch 27/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.8046e-04 - val_loss: 2.8710e-04\n",
      "Epoch 28/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.7045e-04 - val_loss: 3.3278e-04\n",
      "Epoch 29/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.6173e-04 - val_loss: 4.4220e-04\n",
      "Epoch 30/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 3.3326e-04 - val_loss: 4.0256e-04\n",
      "Epoch 31/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 4.0505e-04 - val_loss: 2.9693e-04\n",
      "Epoch 32/100\n",
      "6444/6444 [==============================] - 11s 2ms/sample - loss: 2.8745e-04 - val_loss: 3.8058e-04\n",
      "Validation RMSE:  0.0159533537181224 \n",
      "\n",
      "4  \t4     \n"
     ]
    }
   ],
   "source": [
    "population_size = 5\n",
    "num_generations = 4\n",
    "gene_length = 15\n",
    "\n",
    "# As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, \n",
    "n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \n",
    "                        ngen = num_generations, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución K mejor encontrada a través de GA se puede ver fácilmente usando tools.selBest(population,k = 1). Después, la configuración óptima se puede utilizar para entrenar en el conjunto de entrenamiento completo y probarlo en el conjunto de prueba de espera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep Size:  4 , Num of Units:  11 , Learning rate:  0.0013000000000000002\n",
      "Batch Size:  4 , Num of Epochs:  100\n"
     ]
    }
   ],
   "source": [
    "# Guarda las mejores N solutions - (1, para k=1)\n",
    "best_individuals = tools.selBest(population,k = 1)\n",
    "best_deep_size = None\n",
    "best_num_units = None\n",
    "best_learning_rate = None\n",
    "best_batch_size = None\n",
    "best_epochs = None\n",
    "\n",
    "for bi in best_individuals:\n",
    "    deep_size_bits = BitArray(bi[0:3])\n",
    "    num_units_bits = BitArray(bi[3:8])\n",
    "    learning_rate_bits = BitArray(bi[8:12])\n",
    "    batch_size_bits = BitArray(bi[12:14])\n",
    "    epochs_bits = BitArray(bi[14:])\n",
    "    \n",
    "    best_deep_size = deep_size_bits.uint +2\n",
    "    best_num_units = num_units_bits.uint +1\n",
    "    best_learning_rate = (learning_rate_bits.uint + 1)*10**(-4)\n",
    "    best_batch_size= 2**(batch_size_bits.uint +1)\n",
    "    best_epochs= (epochs_bits.uint +1)*50\n",
    "    print('\\nDeep Size: ', best_deep_size, ', Num of Units: ', best_num_units, ', Learning rate: ', best_learning_rate)\n",
    "    print('Batch Size: ', best_batch_size, \", Num of Epochs: \", best_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8056 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "8056/8056 [==============================] - 13s 2ms/sample - loss: 24.6044 - val_loss: 0.0044\n",
      "Epoch 2/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.4576 - val_loss: 0.0037\n",
      "Epoch 3/100\n",
      "8056/8056 [==============================] - 7s 915us/sample - loss: 0.6582 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "8056/8056 [==============================] - 8s 1ms/sample - loss: 0.2455 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0984 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.9212 - val_loss: 0.0036\n",
      "Epoch 7/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 8/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.5711e-04 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 11/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.0855e-04 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 7.1235e-04 - val_loss: 0.0033\n",
      "Epoch 13/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.6675e-04 - val_loss: 0.0021\n",
      "Epoch 14/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.5306e-04 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.3011e-04 - val_loss: 0.0040\n",
      "Epoch 16/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.1153e-04 - val_loss: 0.0015\n",
      "Epoch 17/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.6168e-04 - val_loss: 0.0017\n",
      "Epoch 18/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.0787e-04 - val_loss: 0.0014\n",
      "Epoch 19/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 9.5340e-04 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.0253e-04 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.6258e-04 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.0846e-04 - val_loss: 0.0018\n",
      "Epoch 23/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.6714e-04 - val_loss: 0.0028\n",
      "Epoch 24/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.3377e-04 - val_loss: 0.0017\n",
      "Epoch 25/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.8844e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.0394e-04 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.5879e-04 - val_loss: 0.0014\n",
      "Epoch 29/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.2998e-04 - val_loss: 7.7096e-04\n",
      "Epoch 30/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9923e-04 - val_loss: 9.8860e-04\n",
      "Epoch 31/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.0924e-04 - val_loss: 8.5634e-04\n",
      "Epoch 32/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.3872e-04 - val_loss: 0.0028\n",
      "Epoch 33/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.3072e-04 - val_loss: 9.5596e-04\n",
      "Epoch 34/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9585e-04 - val_loss: 5.2131e-04\n",
      "Epoch 35/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.3667e-04 - val_loss: 0.0018\n",
      "Epoch 36/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.2179e-04 - val_loss: 7.2760e-04\n",
      "Epoch 37/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.6852e-04 - val_loss: 5.5362e-04\n",
      "Epoch 38/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.9240e-04 - val_loss: 6.0621e-04\n",
      "Epoch 39/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.6038e-04 - val_loss: 9.3514e-04\n",
      "Epoch 40/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9452e-04 - val_loss: 7.2926e-04\n",
      "Epoch 41/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.8824e-04 - val_loss: 4.6151e-04\n",
      "Epoch 42/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 43/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.9847e-04 - val_loss: 9.0722e-04\n",
      "Epoch 44/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.5883e-04 - val_loss: 7.3120e-04\n",
      "Epoch 45/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9411e-04 - val_loss: 7.0272e-04\n",
      "Epoch 46/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.6465e-04 - val_loss: 7.5303e-04\n",
      "Epoch 47/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.9799e-04 - val_loss: 6.2916e-04\n",
      "Epoch 48/100\n",
      "8056/8056 [==============================] - 10s 1ms/sample - loss: 2.6646e-04 - val_loss: 5.1420e-04\n",
      "Epoch 49/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4399e-04 - val_loss: 9.5582e-04\n",
      "Epoch 50/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4254e-04 - val_loss: 6.4074e-04\n",
      "Epoch 51/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.0012e-04 - val_loss: 6.8545e-04\n",
      "Epoch 52/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.6715e-04 - val_loss: 4.1542e-04\n",
      "Epoch 53/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.3878e-04 - val_loss: 0.0010\n",
      "Epoch 54/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9966e-04 - val_loss: 2.7095e-04\n",
      "Epoch 55/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4138e-04 - val_loss: 4.3820e-04\n",
      "Epoch 56/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4269e-04 - val_loss: 3.6357e-04\n",
      "Epoch 57/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.9235e-04 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.8428e-04 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.4856e-04 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.1021e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.6928e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9902e-04 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.6431e-04 - val_loss: 9.7161e-04\n",
      "Epoch 64/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.5170e-04 - val_loss: 9.8821e-04\n",
      "Epoch 65/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9243e-04 - val_loss: 0.0017\n",
      "Epoch 66/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.8305e-04 - val_loss: 0.0013\n",
      "Epoch 67/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4624e-04 - val_loss: 7.6177e-04\n",
      "Epoch 68/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.3624e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.2175e-04 - val_loss: 8.3338e-04\n",
      "Epoch 70/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.7523e-04 - val_loss: 6.0808e-04\n",
      "Epoch 71/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.2500e-04 - val_loss: 0.0013\n",
      "Epoch 73/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.0512e-04 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 4.8865e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.0691e-04 - val_loss: 0.0017\n",
      "Epoch 76/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9922e-04 - val_loss: 8.6876e-04\n",
      "Epoch 77/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.6610e-04 - val_loss: 9.2706e-04\n",
      "Epoch 78/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.3600e-04 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.3862e-04 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4456e-04 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.6850e-04 - val_loss: 9.5362e-04\n",
      "Epoch 82/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.2960e-04 - val_loss: 8.9626e-04\n",
      "Epoch 83/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.9599e-04 - val_loss: 8.0145e-04\n",
      "Epoch 84/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4012e-04 - val_loss: 8.5023e-04\n",
      "Epoch 85/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.2263e-04 - val_loss: 9.2307e-04\n",
      "Epoch 86/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.2335e-04 - val_loss: 6.8228e-04\n",
      "Epoch 87/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 5.7439e-04 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 3.2340e-04 - val_loss: 8.4026e-04\n",
      "Epoch 89/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.8437e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4238e-04 - val_loss: 5.7911e-04\n",
      "Epoch 91/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.4341e-04 - val_loss: 7.8462e-04\n",
      "Epoch 92/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.8756e-04 - val_loss: 8.6403e-04\n",
      "Epoch 93/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.2944e-04 - val_loss: 8.8375e-04\n",
      "Epoch 94/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.1287e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.3149e-04 - val_loss: 6.9262e-04\n",
      "Epoch 96/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.3941e-04 - val_loss: 7.1626e-04\n",
      "Epoch 97/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.1200e-04 - val_loss: 7.4763e-04\n",
      "Epoch 98/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.7233e-04 - val_loss: 6.5963e-04\n",
      "Epoch 99/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.2488e-04 - val_loss: 4.4114e-04\n",
      "Epoch 100/100\n",
      "8056/8056 [==============================] - 11s 1ms/sample - loss: 2.0490e-04 - val_loss: 6.3177e-04\n",
      "Test RMSE:  0.025135022385322774\n"
     ]
    }
   ],
   "source": [
    "# Train the model using best configuration on complete training set \n",
    "#and make predictions on the test set\n",
    "X_train,y_train = prepare_dataset(train_data)\n",
    "X_test, y_test = prepare_dataset(test_data)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(best_num_units, input_shape=(3,)))\n",
    "#     x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "\n",
    "for i in range(best_deep_size):        \n",
    "    model.add(layers.Dense(best_num_units, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=best_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "# callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "#                                    min_delta=1e-4,\n",
    "#                                    patience=3,\n",
    "#                                    restore_best_weights=True)]\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "#                     epochs=best_epochs, callbacks=callbacks, batch_size=best_batch_size, shuffle=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=best_epochs, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
