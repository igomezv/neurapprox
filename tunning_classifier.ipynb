{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "El sistema no puede encontrar el archivo especificado.\n",
      "El sistema no puede encontrar el archivo especificado.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rmdir \".\\logs\\hparam_tuning\" /S /Q  #Para windows\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos: SDSS DR17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        alpha      delta         u         g         r         i         z  \\\n",
      "0  135.689107  32.494632  23.87882  22.27530  20.39501  19.16573  18.79371   \n",
      "1  144.826101  31.274185  24.77759  22.83188  22.58444  21.16812  21.61427   \n",
      "2  142.188790  35.582444  25.26307  22.66389  20.60976  19.34857  18.94827   \n",
      "3  338.741038  -0.402828  22.13682  23.77656  21.61162  20.50454  19.25010   \n",
      "4  345.282593  21.183866  19.43718  17.58028  16.49747  15.97711  15.54461   \n",
      "\n",
      "   redshift  class  \n",
      "0  0.634794      0  \n",
      "1  0.779136      0  \n",
      "2  0.644195      0  \n",
      "3  0.932346      0  \n",
      "4  0.116123      0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./SDSS/star_classification.csv')\n",
    "cols = ['alpha','delta','u','g','r','i','z','redshift','class']\n",
    "data = data[cols]\n",
    "data[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in data[\"class\"]]\n",
    "print(data.head())\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data):\n",
    "    X, Y = np.empty((0)), np.empty((0))\n",
    "    X = data[:, :8]\n",
    "    Y = data[:, 8]\n",
    "    Y = to_categorical(Y, num_classes=3)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = prepare_dataset(data)\n",
    "X_train, X_test, Y_train, Y_test = split(X, Y, test_size = 0.3, random_state = 0)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "lenx, input_shape = np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperpar√°metros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LAYERS =    hp.HParam('layers', hp.Discrete([8, 16]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([4,8,16,32]))\n",
    "HP_LEARNING  = hp.HParam('learning_rate', hp.Discrete([4,8,16,32]))\n",
    "# HP_BATCHSIZE = hp.HParam('batch_size', hp.Discrete([16, 32]))\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max',\n",
    "                                   min_delta=0,\n",
    "                                   patience=3,\n",
    "                                   restore_best_weights=True)]\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC_ACCURACY = 'accuracy'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "# with tf.summary.FileWriter('logs/hparam_tuning', sess.graph):\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess.run(init)\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAYERS, HP_NUM_UNITS, HP_LEARNING],\n",
    "        metrics=[hp.Metric('loss', display_name=\"Accuracy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):    \n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = keras.Sequential()\n",
    "    model.add(Input(shape=(int(X_train.shape[1]),)))\n",
    "    model.add(Dense(hparams[HP_NUM_UNITS], input_shape=(int(X_train.shape[1]),)))\n",
    "    \n",
    "    for i in range(hparams[HP_LAYERS]):        \n",
    "        model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(Dense(3, activation=tf.nn.softmax))\n",
    "     \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING]*10**(-4), beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=CategoricalCrossentropy(),\n",
    "            metrics=[\"categorical_accuracy\"])\n",
    "    \n",
    "    # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test),\n",
    "              callbacks=callbacks, batch_size=batch_size, shuffle=True, verbose=0)\n",
    "\n",
    "    _, loss = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(\"loss\", loss, step=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting trial: run-0\n",
      "{'layers': 8, 'num_units': 4, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 125us/sample - loss: 0.1425 - categorical_accuracy: 0.9578\n",
      "Accuracy: 0.9578 Tiempo transcurrido: 89.89737129211426\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'layers': 8, 'num_units': 4, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 127us/sample - loss: 0.1176 - categorical_accuracy: 0.9647\n",
      "Accuracy: 0.9647 Tiempo transcurrido: 99.82058095932007\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'layers': 8, 'num_units': 4, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 4s 124us/sample - loss: 0.1141 - categorical_accuracy: 0.9683\n",
      "Accuracy: 0.9683333 Tiempo transcurrido: 90.81737971305847\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'layers': 8, 'num_units': 4, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 125us/sample - loss: 0.9561 - categorical_accuracy: 0.5936 - loss: 0\n",
      "Accuracy: 0.59363335 Tiempo transcurrido: 40.76187705993652\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'layers': 8, 'num_units': 8, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 140us/sample - loss: 0.1166 - categorical_accuracy: 0.9644\n",
      "Accuracy: 0.9643667 Tiempo transcurrido: 91.63001346588135\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'layers': 8, 'num_units': 8, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 129us/sample - loss: 0.1566 - categorical_accuracy: 0.9651\n",
      "Accuracy: 0.9651333 Tiempo transcurrido: 68.54588437080383\n",
      "\n",
      "--- Starting trial: run-6\n",
      "{'layers': 8, 'num_units': 8, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 4s 123us/sample - loss: 0.1223 - categorical_accuracy: 0.9665\n",
      "Accuracy: 0.96646667 Tiempo transcurrido: 86.8001480102539\n",
      "\n",
      "--- Starting trial: run-7\n",
      "{'layers': 8, 'num_units': 8, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 148us/sample - loss: 0.1242 - categorical_accuracy: 0.9625\n",
      "Accuracy: 0.96253335 Tiempo transcurrido: 50.15746259689331\n",
      "\n",
      "--- Starting trial: run-8\n",
      "{'layers': 8, 'num_units': 16, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 123us/sample - loss: 0.4031 - categorical_accuracy: 0.9681\n",
      "Accuracy: 0.9680667 Tiempo transcurrido: 90.9347677230835\n",
      "\n",
      "--- Starting trial: run-9\n",
      "{'layers': 8, 'num_units': 16, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 138us/sample - loss: 0.4494 - categorical_accuracy: 0.9656\n",
      "Accuracy: 0.96563333 Tiempo transcurrido: 75.76233196258545\n",
      "\n",
      "--- Starting trial: run-10\n",
      "{'layers': 8, 'num_units': 16, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 5s 157us/sample - loss: 0.1479 - categorical_accuracy: 0.9651\n",
      "Accuracy: 0.9650667 Tiempo transcurrido: 59.02190613746643\n",
      "\n",
      "--- Starting trial: run-11\n",
      "{'layers': 8, 'num_units': 16, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 131us/sample - loss: 0.1166 - categorical_accuracy: 0.9664\n",
      "Accuracy: 0.96643335 Tiempo transcurrido: 81.68121886253357\n",
      "\n",
      "--- Starting trial: run-12\n",
      "{'layers': 8, 'num_units': 32, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 127us/sample - loss: 0.1446 - categorical_accuracy: 0.9677\n",
      "Accuracy: 0.9677 Tiempo transcurrido: 102.35533261299133\n",
      "\n",
      "--- Starting trial: run-13\n",
      "{'layers': 8, 'num_units': 32, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 137us/sample - loss: 0.2852 - categorical_accuracy: 0.9675\n",
      "Accuracy: 0.96746665 Tiempo transcurrido: 81.49226927757263\n",
      "\n",
      "--- Starting trial: run-14\n",
      "{'layers': 8, 'num_units': 32, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 4s 128us/sample - loss: 0.1427 - categorical_accuracy: 0.9708\n",
      "Accuracy: 0.97076666 Tiempo transcurrido: 101.78690218925476\n",
      "\n",
      "--- Starting trial: run-15\n",
      "{'layers': 8, 'num_units': 32, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 129us/sample - loss: 0.1235 - categorical_accuracy: 0.9559\n",
      "Accuracy: 0.9558667 Tiempo transcurrido: 101.54681944847107\n",
      "\n",
      "--- Starting trial: run-16\n",
      "{'layers': 16, 'num_units': 4, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 149us/sample - loss: 0.9777 - categorical_accuracy: 0.5936\n",
      "Accuracy: 0.59363335 Tiempo transcurrido: 52.6174054145813\n",
      "\n",
      "--- Starting trial: run-17\n",
      "{'layers': 16, 'num_units': 4, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 6s 185us/sample - loss: 0.9562 - categorical_accuracy: 0.5936\n",
      "Accuracy: 0.59363335 Tiempo transcurrido: 52.68871855735779\n",
      "\n",
      "--- Starting trial: run-18\n",
      "{'layers': 16, 'num_units': 4, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 5s 183us/sample - loss: 0.9562 - categorical_accuracy: 0.5936\n",
      "Accuracy: 0.59363335 Tiempo transcurrido: 51.21287751197815\n",
      "\n",
      "--- Starting trial: run-19\n",
      "{'layers': 16, 'num_units': 4, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 5s 155us/sample - loss: 0.9562 - categorical_accuracy: 0.5936\n",
      "Accuracy: 0.59363335 Tiempo transcurrido: 52.20032238960266\n",
      "\n",
      "--- Starting trial: run-20\n",
      "{'layers': 16, 'num_units': 8, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 147us/sample - loss: 0.1838 - categorical_accuracy: 0.9573\n",
      "Accuracy: 0.9573333 Tiempo transcurrido: 112.17117285728455\n",
      "\n",
      "--- Starting trial: run-21\n",
      "{'layers': 16, 'num_units': 8, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 145us/sample - loss: 0.1469 - categorical_accuracy: 0.9617\n",
      "Accuracy: 0.9617 Tiempo transcurrido: 115.25564312934875\n",
      "\n",
      "--- Starting trial: run-22\n",
      "{'layers': 16, 'num_units': 8, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 4s 146us/sample - loss: 0.2846 - categorical_accuracy: 0.9513\n",
      "Accuracy: 0.9513 Tiempo transcurrido: 61.865031003952026\n",
      "\n",
      "--- Starting trial: run-23\n",
      "{'layers': 16, 'num_units': 8, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 148us/sample - loss: 0.3433 - categorical_accuracy: 0.9677\n",
      "Accuracy: 0.9677333 Tiempo transcurrido: 113.53527474403381\n",
      "\n",
      "--- Starting trial: run-24\n",
      "{'layers': 16, 'num_units': 16, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 4s 147us/sample - loss: 0.2902 - categorical_accuracy: 0.9634\n",
      "Accuracy: 0.9633667 Tiempo transcurrido: 96.35543990135193\n",
      "\n",
      "--- Starting trial: run-25\n",
      "{'layers': 16, 'num_units': 16, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 4s 148us/sample - loss: 0.2907 - categorical_accuracy: 0.9624\n",
      "Accuracy: 0.9624 Tiempo transcurrido: 81.54649710655212\n",
      "\n",
      "--- Starting trial: run-26\n",
      "{'layers': 16, 'num_units': 16, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 4s 147us/sample - loss: 0.1242 - categorical_accuracy: 0.9634\n",
      "Accuracy: 0.9633667 Tiempo transcurrido: 74.79147291183472\n",
      "\n",
      "--- Starting trial: run-27\n",
      "{'layers': 16, 'num_units': 16, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 4s 147us/sample - loss: 0.1430 - categorical_accuracy: 0.9686\n",
      "Accuracy: 0.96863335 Tiempo transcurrido: 118.57481360435486\n",
      "\n",
      "--- Starting trial: run-28\n",
      "{'layers': 16, 'num_units': 32, 'learning_rate': 4}\n",
      "30000/30000 [==============================] - 5s 156us/sample - loss: 0.2063 - categorical_accuracy: 0.9670\n",
      "Accuracy: 0.967 Tiempo transcurrido: 138.20733642578125\n",
      "\n",
      "--- Starting trial: run-29\n",
      "{'layers': 16, 'num_units': 32, 'learning_rate': 8}\n",
      "30000/30000 [==============================] - 5s 155us/sample - loss: 0.5461 - categorical_accuracy: 0.9688\n",
      "Accuracy: 0.9687667 Tiempo transcurrido: 140.64843845367432\n",
      "\n",
      "--- Starting trial: run-30\n",
      "{'layers': 16, 'num_units': 32, 'learning_rate': 16}\n",
      "30000/30000 [==============================] - 5s 154us/sample - loss: 0.3854 - categorical_accuracy: 0.9681\n",
      "Accuracy: 0.96813333 Tiempo transcurrido: 112.12790870666504\n",
      "\n",
      "--- Starting trial: run-31\n",
      "{'layers': 16, 'num_units': 32, 'learning_rate': 32}\n",
      "30000/30000 [==============================] - 5s 154us/sample - loss: 0.2996 - categorical_accuracy: 0.9665\n",
      "Accuracy: 0.96646667 Tiempo transcurrido: 85.56754183769226\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "datos = []\n",
    "\n",
    "for deep_layers in HP_LAYERS.domain.values:\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for learning_rate in HP_LEARNING.domain.values:\n",
    "#             for batch_size in HP_BATCHSIZE.domain.values:\n",
    "            t = time.time()\n",
    "            hparams = {\n",
    "\n",
    "                HP_LAYERS: deep_layers,\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_LEARNING: learning_rate,\n",
    "#                     HP_BATCHSIZE: batch_size\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('\\n--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            score = run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            t = time.time()-t\n",
    "            session_num += 1\n",
    "            print(\"Accuracy:\", score, \"Tiempo transcurrido:\", t)\n",
    "            \n",
    "            datos.append([deep_layers, num_units, learning_rate, score, t])\n",
    "\n",
    "print(session_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"historial_sdss_tunning.txt\"\n",
    "df = pd.DataFrame(datos, columns = [\"Deep size\", \"Num units\", \"Learning rate\", \"Accuracy\", \"Tiempo de ejecuci√≥n\"])\n",
    "\n",
    "df.sort_values(by=[\"Accuracy\", \"Tiempo de ejecuci√≥n\"], ascending=[0,0], ignore_index=True, inplace=True)\n",
    "\n",
    "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep size</th>\n",
       "      <th>Num units</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Tiempo de ejecuci√≥n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.970767</td>\n",
       "      <td>101.786902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.968767</td>\n",
       "      <td>140.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.968633</td>\n",
       "      <td>118.574814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>90.817380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968133</td>\n",
       "      <td>112.127909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.968067</td>\n",
       "      <td>90.934768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.967733</td>\n",
       "      <td>113.535275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>102.355333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.967467</td>\n",
       "      <td>81.492269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>138.207336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.966467</td>\n",
       "      <td>86.800148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.966467</td>\n",
       "      <td>85.567542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>81.681219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.965633</td>\n",
       "      <td>75.762332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.965133</td>\n",
       "      <td>68.545884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.965067</td>\n",
       "      <td>59.021906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.964700</td>\n",
       "      <td>99.820581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964367</td>\n",
       "      <td>91.630013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963367</td>\n",
       "      <td>96.355440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.963367</td>\n",
       "      <td>74.791473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.962533</td>\n",
       "      <td>50.157463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.962400</td>\n",
       "      <td>81.546497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.961700</td>\n",
       "      <td>115.255643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.957800</td>\n",
       "      <td>89.897371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>112.171173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.955867</td>\n",
       "      <td>101.546819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.951300</td>\n",
       "      <td>61.865031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.593633</td>\n",
       "      <td>52.688719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.593633</td>\n",
       "      <td>52.617405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.593633</td>\n",
       "      <td>52.200322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.593633</td>\n",
       "      <td>51.212878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.593633</td>\n",
       "      <td>40.761877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deep size  Num units  Learning rate  Accuracy  Tiempo de ejecuci√≥n\n",
       "0           8         32             16  0.970767           101.786902\n",
       "1          16         32              8  0.968767           140.648438\n",
       "2          16         16             32  0.968633           118.574814\n",
       "3           8          4             16  0.968333            90.817380\n",
       "4          16         32             16  0.968133           112.127909\n",
       "5           8         16              4  0.968067            90.934768\n",
       "6          16          8             32  0.967733           113.535275\n",
       "7           8         32              4  0.967700           102.355333\n",
       "8           8         32              8  0.967467            81.492269\n",
       "9          16         32              4  0.967000           138.207336\n",
       "10          8          8             16  0.966467            86.800148\n",
       "11         16         32             32  0.966467            85.567542\n",
       "12          8         16             32  0.966433            81.681219\n",
       "13          8         16              8  0.965633            75.762332\n",
       "14          8          8              8  0.965133            68.545884\n",
       "15          8         16             16  0.965067            59.021906\n",
       "16          8          4              8  0.964700            99.820581\n",
       "17          8          8              4  0.964367            91.630013\n",
       "18         16         16              4  0.963367            96.355440\n",
       "19         16         16             16  0.963367            74.791473\n",
       "20          8          8             32  0.962533            50.157463\n",
       "21         16         16              8  0.962400            81.546497\n",
       "22         16          8              8  0.961700           115.255643\n",
       "23          8          4              4  0.957800            89.897371\n",
       "24         16          8              4  0.957333           112.171173\n",
       "25          8         32             32  0.955867           101.546819\n",
       "26         16          8             16  0.951300            61.865031\n",
       "27         16          4              8  0.593633            52.688719\n",
       "28         16          4              4  0.593633            52.617405\n",
       "29         16          4             32  0.593633            52.200322\n",
       "30         16          4             16  0.593633            51.212878\n",
       "31          8          4             32  0.593633            40.761877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tiempo de ejecuci√≥n    0.770105\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[[\"Tiempo de ejecuci√≥n\"]])/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf /tmp/tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%!kill` not found.\n"
     ]
    }
   ],
   "source": [
    "%!kill 13652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
