{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNet import NeuralNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/home/cosmocicatais/simpleMC/chains_bambi/\"\n",
    "chain_lcdm_hd = \"LCDM_phy_HD_nested_dynesty_multi_1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(wdir+chain_lcdm_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14037"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = data[:,2:5]\n",
    "likes = data[:,1]\n",
    "len(likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(likes)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 51,001\n",
      "Trainable params: 51,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = NeuralNet(samples, likes, [3,100, 100, 100, 100, 100, 1], epochs=300, batch_size=8, scale=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/300\n",
      "1404/1404 [==============================] - 1s 806us/step - loss: 3201178.1847 - val_loss: 2519224.5000\n",
      "Epoch 2/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 2576358.3852 - val_loss: 2347978.5000\n",
      "Epoch 3/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 2425696.6522 - val_loss: 2136705.5000\n",
      "Epoch 4/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 2168788.5839 - val_loss: 1392045.0000\n",
      "Epoch 5/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 946784.1369 - val_loss: 139497.0938\n",
      "Epoch 6/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 92868.8344 - val_loss: 32550.2559\n",
      "Epoch 7/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 35520.2596 - val_loss: 21038.6875\n",
      "Epoch 8/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 27517.1907 - val_loss: 17349.7930\n",
      "Epoch 9/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 21326.5553 - val_loss: 11068.6592\n",
      "Epoch 10/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 16531.0763 - val_loss: 7082.6558\n",
      "Epoch 11/300\n",
      "1404/1404 [==============================] - 1s 665us/step - loss: 9688.3247 - val_loss: 4006.3838\n",
      "Epoch 12/300\n",
      "1404/1404 [==============================] - 1s 662us/step - loss: 7937.7656 - val_loss: 3056.3130\n",
      "Epoch 13/300\n",
      "1404/1404 [==============================] - 1s 653us/step - loss: 5657.5038 - val_loss: 2341.0332\n",
      "Epoch 14/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 4317.5456 - val_loss: 2007.9767\n",
      "Epoch 15/300\n",
      "1404/1404 [==============================] - 1s 675us/step - loss: 4080.7467 - val_loss: 3433.0674\n",
      "Epoch 16/300\n",
      "1404/1404 [==============================] - 1s 656us/step - loss: 3926.4196 - val_loss: 1379.5284\n",
      "Epoch 17/300\n",
      "1404/1404 [==============================] - 1s 666us/step - loss: 2506.6191 - val_loss: 1811.9391\n",
      "Epoch 18/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 2401.0152 - val_loss: 1492.2834\n",
      "Epoch 19/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 3081.9653 - val_loss: 1356.8109\n",
      "Epoch 20/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 2203.2476 - val_loss: 882.9177\n",
      "Epoch 21/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 3211.5048 - val_loss: 1183.6538\n",
      "Epoch 22/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 2891.4758 - val_loss: 1103.0088\n",
      "Epoch 23/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 2180.5898 - val_loss: 801.6369\n",
      "Epoch 24/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 2968.9389 - val_loss: 873.5647\n",
      "Epoch 25/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 1685.5618 - val_loss: 3510.5002\n",
      "Epoch 26/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 1862.0408 - val_loss: 4100.1230\n",
      "Epoch 27/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 2261.2016 - val_loss: 1375.9672\n",
      "Epoch 28/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 4333.4101 - val_loss: 9336.0859\n",
      "Epoch 29/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 4345.0225 - val_loss: 666.8271\n",
      "Epoch 30/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 8020.7453 - val_loss: 574.6437\n",
      "Epoch 31/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 2115.0763 - val_loss: 1082.3087\n",
      "Epoch 32/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 2437.1403 - val_loss: 535.4960\n",
      "Epoch 33/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 1180.2193 - val_loss: 1608.9081\n",
      "Epoch 34/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 2499.1383 - val_loss: 1678.2372\n",
      "Epoch 35/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 5808.2042 - val_loss: 536.0798\n",
      "Epoch 36/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 1745.9468 - val_loss: 495.2583\n",
      "Epoch 37/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 904.2908 - val_loss: 1153.1843\n",
      "Epoch 38/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 4029.3503 - val_loss: 496.0623\n",
      "Epoch 39/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 947.9295 - val_loss: 508.2609\n",
      "Epoch 40/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 1721.8259 - val_loss: 2082.8601\n",
      "Epoch 41/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 1974.2525 - val_loss: 736.9169\n",
      "Epoch 42/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 1176.1404 - val_loss: 1625.2080\n",
      "Epoch 43/300\n",
      "1404/1404 [==============================] - 1s 639us/step - loss: 2388.0416 - val_loss: 734.2664\n",
      "Epoch 44/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 753.4304 - val_loss: 706.5944\n",
      "Epoch 45/300\n",
      "1404/1404 [==============================] - 1s 653us/step - loss: 5387.1986 - val_loss: 440.4194\n",
      "Epoch 46/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 2570.2626 - val_loss: 8627.8672\n",
      "Epoch 47/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 4384.0904 - val_loss: 366.0853\n",
      "Epoch 48/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 1511.7098 - val_loss: 3108.5037\n",
      "Epoch 49/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 1293.7185 - val_loss: 1739.6154\n",
      "Epoch 50/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 1919.5691 - val_loss: 628.2242\n",
      "Epoch 51/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 1011.9703 - val_loss: 627.3264\n",
      "Epoch 52/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 1900.2092 - val_loss: 1108.8082\n",
      "Epoch 53/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 672.2120 - val_loss: 317.2822\n",
      "Epoch 54/300\n",
      "1404/1404 [==============================] - 1s 637us/step - loss: 6003.5714 - val_loss: 327.4939\n",
      "Epoch 55/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 750.5566 - val_loss: 324.9439\n",
      "Epoch 56/300\n",
      "1404/1404 [==============================] - 1s 632us/step - loss: 2409.6025 - val_loss: 349.5372\n",
      "Epoch 57/300\n",
      "1404/1404 [==============================] - 1s 637us/step - loss: 2061.3138 - val_loss: 286.2067\n",
      "Epoch 58/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 881.3990 - val_loss: 2033.2522\n",
      "Epoch 59/300\n",
      "1404/1404 [==============================] - 1s 629us/step - loss: 1526.2072 - val_loss: 235.0581\n",
      "Epoch 60/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 3573.5273 - val_loss: 286.2394\n",
      "Epoch 61/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 1367.5700 - val_loss: 496.0200\n",
      "Epoch 62/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 971.8640 - val_loss: 36811.0273\n",
      "Epoch 63/300\n",
      "1404/1404 [==============================] - 1s 668us/step - loss: 6470.7705 - val_loss: 697.5182\n",
      "Epoch 64/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 1476.8575 - val_loss: 294.2683\n",
      "Epoch 65/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 999.4380 - val_loss: 867.8323\n",
      "Epoch 66/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 2588.7043 - val_loss: 264.9578\n",
      "Epoch 67/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 663.3356 - val_loss: 613.5961\n",
      "Epoch 68/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 6102.5843 - val_loss: 336.8319\n",
      "Epoch 69/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 1760.0105 - val_loss: 7091.1504\n",
      "Epoch 70/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 2233.3679 - val_loss: 183.7873\n",
      "Epoch 71/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 456.5744 - val_loss: 883.7863\n",
      "Epoch 72/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 1469.3644 - val_loss: 266.6123\n",
      "Epoch 73/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 1618.2498 - val_loss: 183.7224\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 1s 645us/step - loss: 2023.5329 - val_loss: 192.1895\n",
      "Epoch 75/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 307.5152 - val_loss: 406.5197\n",
      "Epoch 76/300\n",
      "1404/1404 [==============================] - 1s 636us/step - loss: 620.2244 - val_loss: 757.4835\n",
      "Epoch 77/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 1548.4828 - val_loss: 244.2943\n",
      "Epoch 78/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 1087.0732 - val_loss: 173.3024\n",
      "Epoch 79/300\n",
      "1404/1404 [==============================] - 1s 635us/step - loss: 486.6330 - val_loss: 413.0063\n",
      "Epoch 80/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 3982.2865 - val_loss: 149.4454\n",
      "Epoch 81/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 3166.2719 - val_loss: 387.0746\n",
      "Epoch 82/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 3703.6801 - val_loss: 202.8858\n",
      "Epoch 83/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 217.7966 - val_loss: 10563.1094\n",
      "Epoch 84/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 2788.2204 - val_loss: 427.3287\n",
      "Epoch 85/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 1880.3710 - val_loss: 124.3298\n",
      "Epoch 86/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 372.3310 - val_loss: 703.5861\n",
      "Epoch 87/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 1433.8597 - val_loss: 329.2004\n",
      "Epoch 88/300\n",
      "1404/1404 [==============================] - 1s 637us/step - loss: 902.3455 - val_loss: 218.0853\n",
      "Epoch 89/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 696.3040 - val_loss: 132.4676\n",
      "Epoch 90/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 1184.6514 - val_loss: 6112.3540\n",
      "Epoch 91/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 4902.3005 - val_loss: 418.8175\n",
      "Epoch 92/300\n",
      "1404/1404 [==============================] - 1s 637us/step - loss: 521.7309 - val_loss: 2273.0547\n",
      "Epoch 93/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 1790.4335 - val_loss: 358.2585\n",
      "Epoch 94/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 308.7520 - val_loss: 751.0021\n",
      "Epoch 95/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 1364.0950 - val_loss: 84.6445\n",
      "Epoch 96/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 1077.8028 - val_loss: 95.6035\n",
      "Epoch 97/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 2097.1909 - val_loss: 389.6986\n",
      "Epoch 98/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 1558.6332 - val_loss: 627.7208\n",
      "Epoch 99/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 794.1476 - val_loss: 2162.4282\n",
      "Epoch 100/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 910.2260 - val_loss: 474.2571\n",
      "Epoch 101/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 1041.1237 - val_loss: 369.8799\n",
      "Epoch 102/300\n",
      "1404/1404 [==============================] - 1s 658us/step - loss: 560.4047 - val_loss: 249.8985\n",
      "Epoch 103/300\n",
      "1404/1404 [==============================] - 1s 667us/step - loss: 2677.1524 - val_loss: 159.4460\n",
      "Epoch 104/300\n",
      "1404/1404 [==============================] - 1s 664us/step - loss: 326.1822 - val_loss: 686.2749\n",
      "Epoch 105/300\n",
      "1404/1404 [==============================] - 1s 664us/step - loss: 935.3582 - val_loss: 80.2977\n",
      "Epoch 106/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 1134.2656 - val_loss: 96.5515\n",
      "Epoch 107/300\n",
      "1404/1404 [==============================] - 1s 665us/step - loss: 552.8943 - val_loss: 138.8767\n",
      "Epoch 108/300\n",
      "1404/1404 [==============================] - 1s 662us/step - loss: 651.4124 - val_loss: 91.6284\n",
      "Epoch 109/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 483.9362 - val_loss: 642.1023\n",
      "Epoch 110/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 8249.2845 - val_loss: 111.5034\n",
      "Epoch 111/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 214.3056 - val_loss: 703.6404\n",
      "Epoch 112/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 1244.7000 - val_loss: 134.8869\n",
      "Epoch 113/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 398.2944 - val_loss: 2362.2417\n",
      "Epoch 114/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 2610.1657 - val_loss: 234.4230\n",
      "Epoch 115/300\n",
      "1404/1404 [==============================] - 1s 679us/step - loss: 1348.6494 - val_loss: 349.2253\n",
      "Epoch 116/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 489.2255 - val_loss: 77.1120\n",
      "Epoch 117/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 853.3891 - val_loss: 169.0909\n",
      "Epoch 118/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 836.8022 - val_loss: 152.0221\n",
      "Epoch 119/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 2369.7210 - val_loss: 404.4129\n",
      "Epoch 120/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 480.8651 - val_loss: 324.0568\n",
      "Epoch 121/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 1481.1347 - val_loss: 77.6846\n",
      "Epoch 122/300\n",
      "1404/1404 [==============================] - 1s 656us/step - loss: 596.5898 - val_loss: 116.1665\n",
      "Epoch 123/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 1076.3840 - val_loss: 594.9366\n",
      "Epoch 124/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 637.6601 - val_loss: 56.0461\n",
      "Epoch 125/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 1308.5096 - val_loss: 140.4248\n",
      "Epoch 126/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 1139.4226 - val_loss: 97.1142\n",
      "Epoch 127/300\n",
      "1404/1404 [==============================] - 1s 672us/step - loss: 491.9159 - val_loss: 695.3898\n",
      "Epoch 128/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 1369.7576 - val_loss: 91.9835\n",
      "Epoch 129/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 5322.7605 - val_loss: 53.4461\n",
      "Epoch 130/300\n",
      "1404/1404 [==============================] - 1s 663us/step - loss: 524.0130 - val_loss: 79.7737\n",
      "Epoch 131/300\n",
      "1404/1404 [==============================] - 1s 639us/step - loss: 1572.0085 - val_loss: 72.0972\n",
      "Epoch 132/300\n",
      "1404/1404 [==============================] - 1s 643us/step - loss: 571.2554 - val_loss: 174.6733\n",
      "Epoch 133/300\n",
      "1404/1404 [==============================] - 1s 641us/step - loss: 803.6189 - val_loss: 916.1964\n",
      "Epoch 134/300\n",
      "1404/1404 [==============================] - 1s 646us/step - loss: 817.0191 - val_loss: 110.3761\n",
      "Epoch 135/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 561.3320 - val_loss: 151.7427\n",
      "Epoch 136/300\n",
      "1404/1404 [==============================] - 1s 639us/step - loss: 1618.0446 - val_loss: 1369.2927\n",
      "Epoch 137/300\n",
      "1404/1404 [==============================] - 1s 639us/step - loss: 314.7820 - val_loss: 1010.5217\n",
      "Epoch 138/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 1260.4884 - val_loss: 94.4212\n",
      "Epoch 139/300\n",
      "1404/1404 [==============================] - 1s 634us/step - loss: 1889.6199 - val_loss: 443.9674\n",
      "Epoch 140/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 271.9495 - val_loss: 487.5082\n",
      "Epoch 141/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 3421.4763 - val_loss: 90.1421\n",
      "Epoch 142/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 349.8688 - val_loss: 121.9331\n",
      "Epoch 143/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 1618.1964 - val_loss: 112.5946\n",
      "Epoch 144/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 279.8963 - val_loss: 809.0075\n",
      "Epoch 145/300\n",
      "1404/1404 [==============================] - 1s 644us/step - loss: 2055.9495 - val_loss: 279.6591\n",
      "Epoch 146/300\n",
      "1404/1404 [==============================] - 1s 649us/step - loss: 471.1380 - val_loss: 191.1149\n",
      "Epoch 147/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 1046.6697 - val_loss: 139.2462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 3519.5106 - val_loss: 105.2683\n",
      "Epoch 149/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 616.6328 - val_loss: 1115.4146\n",
      "Epoch 150/300\n",
      "1404/1404 [==============================] - 1s 639us/step - loss: 430.1705 - val_loss: 397.0367\n",
      "Epoch 151/300\n",
      "1404/1404 [==============================] - 1s 633us/step - loss: 2416.8809 - val_loss: 169.3396\n",
      "Epoch 152/300\n",
      "1404/1404 [==============================] - 1s 645us/step - loss: 1526.7363 - val_loss: 52.4103\n",
      "Epoch 153/300\n",
      "1404/1404 [==============================] - 1s 661us/step - loss: 531.4759 - val_loss: 49.1243\n",
      "Epoch 154/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 1301.6339 - val_loss: 52.8262\n",
      "Epoch 155/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 923.4208 - val_loss: 153.1557\n",
      "Epoch 156/300\n",
      "1404/1404 [==============================] - 1s 688us/step - loss: 816.4928 - val_loss: 61.6824\n",
      "Epoch 157/300\n",
      "1404/1404 [==============================] - 1s 677us/step - loss: 849.3585 - val_loss: 197.2423\n",
      "Epoch 158/300\n",
      "1404/1404 [==============================] - 1s 734us/step - loss: 694.0762 - val_loss: 101.3800\n",
      "Epoch 159/300\n",
      "1404/1404 [==============================] - 1s 799us/step - loss: 2321.2430 - val_loss: 84.7985\n",
      "Epoch 160/300\n",
      "1404/1404 [==============================] - 1s 683us/step - loss: 625.8232 - val_loss: 430.5240\n",
      "Epoch 161/300\n",
      "1404/1404 [==============================] - 1s 658us/step - loss: 791.2976 - val_loss: 1027.7198\n",
      "Epoch 162/300\n",
      "1404/1404 [==============================] - 1s 663us/step - loss: 498.0592 - val_loss: 5213.4692\n",
      "Epoch 163/300\n",
      "1404/1404 [==============================] - 1s 663us/step - loss: 2716.7650 - val_loss: 96.2313\n",
      "Epoch 164/300\n",
      "1404/1404 [==============================] - 1s 664us/step - loss: 6974.0445 - val_loss: 52.7080\n",
      "Epoch 165/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 163.7300 - val_loss: 89.5429\n",
      "Epoch 166/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 674.9314 - val_loss: 137.5073\n",
      "Epoch 167/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 217.7546 - val_loss: 593.9420\n",
      "Epoch 168/300\n",
      "1404/1404 [==============================] - 1s 659us/step - loss: 2329.1066 - val_loss: 87.4416\n",
      "Epoch 169/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 1224.8549 - val_loss: 647.2300\n",
      "Epoch 170/300\n",
      "1404/1404 [==============================] - 1s 640us/step - loss: 491.9766 - val_loss: 302.2313\n",
      "Epoch 171/300\n",
      "1404/1404 [==============================] - 1s 637us/step - loss: 448.1062 - val_loss: 9108.1348\n",
      "Epoch 172/300\n",
      "1404/1404 [==============================] - 1s 638us/step - loss: 1244.0633 - val_loss: 186.4118\n",
      "Epoch 173/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 625.3078 - val_loss: 225.0496\n",
      "Epoch 174/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 1276.4873 - val_loss: 200.9240\n",
      "Epoch 175/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 1190.3807 - val_loss: 104.4335\n",
      "Epoch 176/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 544.2849 - val_loss: 57.0784\n",
      "Epoch 177/300\n",
      "1404/1404 [==============================] - 1s 642us/step - loss: 346.8310 - val_loss: 133.3364\n",
      "Epoch 178/300\n",
      "1404/1404 [==============================] - 1s 662us/step - loss: 750.2081 - val_loss: 99.2856\n",
      "Epoch 179/300\n",
      "1404/1404 [==============================] - 1s 659us/step - loss: 841.3578 - val_loss: 91.0732\n",
      "Epoch 180/300\n",
      "1404/1404 [==============================] - 1s 668us/step - loss: 720.7570 - val_loss: 183.9386\n",
      "Epoch 181/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 1799.1148 - val_loss: 332.1988\n",
      "Epoch 182/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 1304.4905 - val_loss: 421.8338\n",
      "Epoch 183/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 4657.5197 - val_loss: 80.9010\n",
      "Epoch 184/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 456.1189 - val_loss: 79.4669\n",
      "Epoch 185/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 344.5147 - val_loss: 181.2545\n",
      "Epoch 186/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 1169.2845 - val_loss: 341.1450\n",
      "Epoch 187/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 2320.0763 - val_loss: 3997.0684\n",
      "Epoch 188/300\n",
      "1404/1404 [==============================] - 1s 648us/step - loss: 3155.6314 - val_loss: 61.5348\n",
      "Epoch 189/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 341.0345 - val_loss: 112.8021\n",
      "Epoch 190/300\n",
      "1404/1404 [==============================] - 1s 653us/step - loss: 1667.3182 - val_loss: 107.2420\n",
      "Epoch 191/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 1545.8094 - val_loss: 72.6554\n",
      "Epoch 192/300\n",
      "1404/1404 [==============================] - 1s 653us/step - loss: 147.2771 - val_loss: 1042.6709\n",
      "Epoch 193/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 3982.7917 - val_loss: 38.3594\n",
      "Epoch 194/300\n",
      "1404/1404 [==============================] - 1s 647us/step - loss: 1864.8917 - val_loss: 311.7722\n",
      "Epoch 195/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 1264.5096 - val_loss: 189.0204\n",
      "Epoch 196/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 2006.3866 - val_loss: 50.8461\n",
      "Epoch 197/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 459.7646 - val_loss: 197.5171\n",
      "Epoch 198/300\n",
      "1404/1404 [==============================] - 1s 661us/step - loss: 926.1964 - val_loss: 520.8742\n",
      "Epoch 199/300\n",
      "1404/1404 [==============================] - 1s 661us/step - loss: 764.2772 - val_loss: 253.3795\n",
      "Epoch 200/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 1648.5183 - val_loss: 75.1023\n",
      "Epoch 201/300\n",
      "1404/1404 [==============================] - 1s 650us/step - loss: 171.4303 - val_loss: 56.8610\n",
      "Epoch 202/300\n",
      "1404/1404 [==============================] - 1s 664us/step - loss: 482.3085 - val_loss: 3331.4307\n",
      "Epoch 203/300\n",
      "1404/1404 [==============================] - 1s 663us/step - loss: 853.7102 - val_loss: 375.4994\n",
      "Epoch 204/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 405.3120 - val_loss: 2403.5076\n",
      "Epoch 205/300\n",
      "1404/1404 [==============================] - 1s 658us/step - loss: 1364.5098 - val_loss: 481.0133\n",
      "Epoch 206/300\n",
      "1404/1404 [==============================] - 1s 658us/step - loss: 679.6729 - val_loss: 126.5958\n",
      "Epoch 207/300\n",
      "1404/1404 [==============================] - 1s 661us/step - loss: 835.8329 - val_loss: 61.7044\n",
      "Epoch 208/300\n",
      "1404/1404 [==============================] - 1s 654us/step - loss: 888.1422 - val_loss: 201.4152\n",
      "Epoch 209/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 746.3117 - val_loss: 5928.8730\n",
      "Epoch 210/300\n",
      "1404/1404 [==============================] - 1s 657us/step - loss: 1504.3302 - val_loss: 100.7078\n",
      "Epoch 211/300\n",
      "1404/1404 [==============================] - 1s 656us/step - loss: 274.6855 - val_loss: 107.6626\n",
      "Epoch 212/300\n",
      "1404/1404 [==============================] - 1s 659us/step - loss: 789.9129 - val_loss: 3697.9067\n",
      "Epoch 213/300\n",
      "1404/1404 [==============================] - 1s 666us/step - loss: 403.1387 - val_loss: 58.0069\n",
      "Epoch 214/300\n",
      "1404/1404 [==============================] - 1s 666us/step - loss: 1515.3371 - val_loss: 700.0591\n",
      "Epoch 215/300\n",
      "1404/1404 [==============================] - 1s 661us/step - loss: 749.4488 - val_loss: 1015.8323\n",
      "Epoch 216/300\n",
      "1404/1404 [==============================] - 1s 656us/step - loss: 852.3544 - val_loss: 60.0355\n",
      "Epoch 217/300\n",
      "1404/1404 [==============================] - 1s 660us/step - loss: 596.7700 - val_loss: 787.1269\n",
      "Epoch 218/300\n",
      "1404/1404 [==============================] - 1s 663us/step - loss: 607.7327 - val_loss: 953.1552\n",
      "Epoch 219/300\n",
      "1404/1404 [==============================] - 1s 668us/step - loss: 1435.4599 - val_loss: 422.6325\n",
      "Epoch 220/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 287.8009 - val_loss: 630.7308\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 1s 660us/step - loss: 407.0076 - val_loss: 384.4939\n",
      "Epoch 222/300\n",
      "1404/1404 [==============================] - 1s 662us/step - loss: 968.2766 - val_loss: 86.4857\n",
      "Epoch 223/300\n",
      "1404/1404 [==============================] - 1s 653us/step - loss: 590.2561 - val_loss: 329.1300\n",
      "Epoch 224/300\n",
      "1404/1404 [==============================] - 1s 652us/step - loss: 823.1651 - val_loss: 6569.3306\n",
      "Epoch 225/300\n",
      "1404/1404 [==============================] - 1s 651us/step - loss: 450.1012 - val_loss: 93.4794\n",
      "Epoch 226/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 308.1202 - val_loss: 230.6597\n",
      "Epoch 227/300\n",
      "1404/1404 [==============================] - 1s 655us/step - loss: 1152.1897 - val_loss: 49.8433\n",
      "Epoch 228/300\n",
      " 696/1404 [=============>................] - ETA: 0s - loss: 1201.9401"
     ]
    }
   ],
   "source": [
    "network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot(ylogscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(len(likes)-1)\n",
    "# r = np.argmin(likes)\n",
    "test_sample = samples[r]\n",
    "\n",
    "new_vector = np.array(test_sample).reshape(1,3)\n",
    "# new_vector = np.array([0.7,0.5,0.5])\n",
    "prediction = network.predict(new_vector)\n",
    "\n",
    "\n",
    "print(\"Predicción: {}\".format(float(prediction)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes[r], samples[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(likes)\n",
    "plt.plot(predictions)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.save_model('hzlike', path='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
