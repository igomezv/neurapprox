{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n",
        "!pip install bitstring\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/neuroapprox/elitism.py /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYc45CWnJvmp",
        "outputId": "1d38116b-48d2-4a15-c9c2-5794fe3745f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (3.1.9)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WadF7ROCIukU",
        "outputId": "46588aec-8b5f-40dd-e766-7549288a96f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elitism succesfully imported\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import time, os\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import random\n",
        "from math import floor\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from scipy.stats import bernoulli\n",
        "\n",
        "# import deap\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "from bitstring import BitArray\n",
        "\n",
        "from elitism import eaSimpleWithElitism, main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CB_1KdgUIukr"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "tf.config.optimizer.set_jit(True)\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J9p2IgUMIukt"
      },
      "outputs": [],
      "source": [
        "#algorithm for splitting the dataset into training and validation \n",
        "def split(X,Y,porcent): #porcent must be between 0 and 1, it is the asigned porcent to the training dataset.\n",
        "    n=floor(porcent*len(X))\n",
        "    index=random.sample(range(len(X)),n)\n",
        "    X_learn=[]\n",
        "    Y_learn=[]\n",
        "    for i in index:\n",
        "        X_learn.append(X[i])\n",
        "        Y_learn.append(Y[i])\n",
        "    X_val=np.delete(X,index, axis=0)\n",
        "    Y_val=np.delete(Y,index, axis=0)\n",
        "    \n",
        "    X_learn=np.array(X_learn)\n",
        "    Y_learn=np.array(Y_learn)\n",
        "    return X_learn,Y_learn,X_val,Y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2cbr88iMIukw"
      },
      "outputs": [],
      "source": [
        "O_m=np.arange(0.1,0.51,0.01)\n",
        "H_0=np.arange(66,81,1)\n",
        "t=np.linspace(0,-12,50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rF3YyuMiIuky"
      },
      "outputs": [],
      "source": [
        "def RHS(Omega_i, lna, gamma=0):\n",
        "    x, y, z, H = Omega_i\n",
        "    #x, y, z = Omega_i\n",
        "    pi = 3*x + 4*y\n",
        "    return [x*(-3 + pi), y*(-4 + pi), z*pi, -0.5*H*pi]\n",
        "    #return [x*(-3 + pi), y*(-4 + pi), z*pi]\n",
        "\n",
        "def EDO(t,Om,H0):\n",
        "    #t,Or,Om,Ol=X\n",
        "    Or=0.0001\n",
        "    Ol=1-Or-Om\n",
        "    #H0 = 70.\n",
        "    y0 = [Om, Or, Ol, H0]\n",
        "    result = odeint(RHS, y0, t)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9eyIdxXQIukz"
      },
      "outputs": [],
      "source": [
        "#lets generate the cartesian product between the intervals\n",
        "Y0=[]\n",
        "#este ciclo llena la lista fijando un Om y pasando todos los Or\n",
        "for i in O_m:\n",
        "    for j in H_0:\n",
        "        Y0.extend(EDO(t,i,j))\n",
        "Y0=np.array(Y0)\n",
        "\n",
        "X0=[]\n",
        "for Om in O_m:\n",
        "    for H0 in H_0:\n",
        "        for T in t:\n",
        "            X0.append([T,Om,H0])\n",
        "X0=np.array(X0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MI4XZKdFIuk1"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
        "Y2 = scaler.fit_transform(Y0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC1N_CJLIuk3",
        "outputId": "b6f036d3-a2be-4324-ff78-9a9b5c21001f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feactures= \n",
            " [[  0.           0.1         66.        ]\n",
            " [ -0.24489796   0.1         66.        ]\n",
            " [ -0.48979592   0.1         66.        ]\n",
            " ...\n",
            " [-11.51020408   0.5         80.        ]\n",
            " [-11.75510204   0.5         80.        ]\n",
            " [-12.           0.5         80.        ]]\n",
            "\n",
            "\n",
            "labels= \n",
            " [[9.47515373e-02 0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
            " [1.83608702e-01 1.41110961e-04 9.01997379e-01 1.62358493e-10]\n",
            " [3.22333902e-01 4.33937896e-04 7.48914062e-01 4.77144941e-10]\n",
            " ...\n",
            " [4.20164900e-02 9.58104047e-01 5.58399792e-11 3.78984027e-01]\n",
            " [3.19464665e-02 9.68145182e-01 5.73926563e-11 6.15280156e-01]\n",
            " [2.39153274e-02 9.76153281e-01 5.75109456e-11 1.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "#Now, here are the datasets\n",
        "print('feactures= \\n',X0)\n",
        "print('\\n')\n",
        "print('labels= \\n',Y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cg5rKwuTIuk6"
      },
      "outputs": [],
      "source": [
        "split_size = 0.5\n",
        "X_train, Y_train, X_test, Y_test = split(X0, Y2, split_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CpTfwnfVIuk8"
      },
      "outputs": [],
      "source": [
        "SC_DEEP       = np.arange(2, 5+1, 1, dtype=int)                        # Number of deep layers (4)\n",
        "SC_NUM_UNITS  = np.array([50, 100, 150, 200], dtype=int)         # Number of fully conected neurons (3)\n",
        "SC_LEARNING   = np.logspace(-5,-3, endpoint=True, num=3)                      # Learning rates (3)\n",
        "SC_BATCH      = np.arange(4,8+1,4, dtype=int)                                # Batch sizes (2)\n",
        "# SC_ACTIVATION = [f1, f2, f3, f4]                 # Activation function layers (2)\n",
        "\n",
        "BOUNDS = [SC_DEEP,SC_NUM_UNITS,SC_LEARNING,SC_BATCH]\n",
        "DOWN, UP = [], []\n",
        "for i in range(len(BOUNDS)):\n",
        "    DOWN.append(BOUNDS[i][0])\n",
        "    UP.append(BOUNDS[i][-1])\n",
        "\n",
        "DIMS = 4              # boundaries for all dimensions\n",
        "\n",
        "my_callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "                               monitor='val_loss', mode='min',\n",
        "                               min_delta=4e-7, \n",
        "                               patience=5,\n",
        "                               verbose=1,\n",
        "                            #    baseline=0,\n",
        "                               restore_best_weights=1)\n",
        "#                 keras.callbacks.TensorBoard(\n",
        "#                                log_dir='./logs'),\n",
        "#                 keras.callbacks.ReduceLROnPlateau(\n",
        "#                                monitor='val_loss', factor=0.5,\n",
        "#                                patience=6, min_lr=0,\n",
        "#                                verbose=1)\n",
        "               ] \n",
        "    \n",
        "epochs = 100\n",
        "# epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOUNDS[1][0]\n",
        "# DOWN, \n",
        "# UP"
      ],
      "metadata": {
        "id": "RkWQH1r1zGly"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5e07dsBBIulB"
      },
      "outputs": [],
      "source": [
        "# Produces train and val splits.\n",
        "X_test, Y_test, X_val, Y_val = split(X_test, Y_test, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gNc-UrBaIulF"
      },
      "outputs": [],
      "source": [
        "def train_evaluate(ga_individual_solution):   \n",
        "    t = time.time()\n",
        "    t_total = 0\n",
        "    \n",
        "    # Decode GA solution to integer for window_size and num_units\n",
        "    deep_layers   = int(ga_individual_solution[0])   \n",
        "    num_units     = int(ga_individual_solution[1])\n",
        "    learning_rate = ga_individual_solution[2]\n",
        "    batch_size    = int(ga_individual_solution[3])    \n",
        "# #     activation_f  = BitArray(ga_individual_solution[4])   # (2)   Solo se consideran las 2 primeras\n",
        "    \n",
        "    print('\\n--------------- Starting trial:', population_size*(max_generations+1)-len(ss), \"---------------\")\n",
        "    print('Deep layers:',deep_layers,', Number of neurons:',num_units,\", Learning rate:\",learning_rate,', Batch size:',batch_size)\n",
        "    \n",
        "    # Train model and predict on validation set\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Dense(int(X_train.shape[1])))\n",
        "    \n",
        "    for i in range(deep_layers):        \n",
        "        model.add(Dense(num_units, activation='elu'))\n",
        "#             model.add(keras.layers.Dropout(0.3))\n",
        "    model.add(Dense(4, activation='linear'))\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mean_squared_error'])\n",
        "    # model.compile(optimizer=optimizer, loss='mse')\n",
        "    model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_val, Y_val),\n",
        "              callbacks=my_callbacks, batch_size=batch_size, shuffle=False, verbose=0)\n",
        "    \n",
        "    loss, score = model.evaluate(X_val, Y_val)    \n",
        "    t = time.time()-t\n",
        "    ss.pop(0)\n",
        "    print(\"Loss:\", score, \", Elapsed time:\", t)\n",
        "    print(\"-------------------------------------------------\\n\")\n",
        "#     print(loss, score)\n",
        "\n",
        "    # datos.append([deep_layers, num_units, learning_rate, batch_size loss, score, t])\n",
        "    datos.append([deep_layers, num_units, learning_rate, batch_size, loss, score, t])\n",
        "    \n",
        "    return loss,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbb5Ka2WIulH",
        "outputId": "2ac69637-b808-4341-9c04-ce076113109d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15375, 3), (7687, 3), (7688, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UfeWOrpHIulJ"
      },
      "outputs": [],
      "source": [
        "from deap import tools\n",
        "from deap import algorithms\n",
        "\n",
        "def eaSimpleWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
        "             halloffame=None, verbose=__debug__):\n",
        "    \"\"\"This algorithm is similar to DEAP eaSimple() algorithm, with the modification that\n",
        "    halloffame is used to implement an elitism mechanism. The individuals contained in the\n",
        "    halloffame are directly injected into the next generation and are not subject to the\n",
        "    genetic operators of selection, crossover and mutation.\n",
        "    \"\"\"\n",
        "    logbook = tools.Logbook()\n",
        "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    if halloffame is None:\n",
        "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
        "\n",
        "    halloffame.update(population)\n",
        "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
        "\n",
        "    record = stats.compile(population) if stats else {}\n",
        "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
        "    if verbose:\n",
        "        print(logbook.stream)\n",
        "\n",
        "    # Begin the generational process\n",
        "    for gen in range(1, ngen + 1):\n",
        "\n",
        "        # Select the next generation individuals\n",
        "        offspring = toolbox.select(population, len(population) - hof_size)\n",
        "\n",
        "        # Vary the pool of individuals\n",
        "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
        "\n",
        "        # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        # add the best back to population:\n",
        "        offspring.extend(halloffame.items)\n",
        "\n",
        "        # Update the hall of fame with the generated individuals\n",
        "        halloffame.update(offspring)\n",
        "\n",
        "        # Replace the current population by the offspring\n",
        "        population[:] = offspring\n",
        "\n",
        "        # Append the current generation statistics to the logbook\n",
        "        record = stats.compile(population) if stats else {}\n",
        "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
        "        if verbose:\n",
        "            print(logbook.stream)\n",
        "\n",
        "    return population, logbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ye9sghsFIulM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k):\n",
        "    \n",
        "    # Genetic Algorithm constants:\n",
        "    P_CROSSOVER = 0.9        # probability for crossover\n",
        "    P_MUTATION = 0.3         # probability for mutating an individual\n",
        "    HALL_OF_FAME_SIZE = 1    # Best individuals that pass to the other generation\n",
        "    CROWDING_FACTOR = 20.0   # crowding factor for crossover and mutation\n",
        "    \n",
        "    # set the random seed:\n",
        "    toolbox = base.Toolbox()\n",
        "\n",
        "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
        "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
        "    creator.create('FitnessMin', base.Fitness, weights = [-1.0])\n",
        "    creator.create('Individual', list , fitness = creator.FitnessMin)\n",
        "\n",
        "    # helper function for creating random real numbers uniformly distributed within a given range [low, up]\n",
        "    def randomInt(BOUNDS, DIMS):\n",
        "        temp = []\n",
        "        for i in range(DIMS):\n",
        "            temp.append(random.choices(BOUNDS[i])[0])\n",
        "        return temp\n",
        "\n",
        "    # create an operator that randomly returns a float in the desired range and dimension:\n",
        "    toolbox.register(\"attrInt\", randomInt, BOUNDS, DIMS)\n",
        "\n",
        "    # create the individual operator to fill up an Individual instance:\n",
        "    toolbox.register('individual', tools.initIterate, creator.Individual, toolbox.attrInt)\n",
        "\n",
        "    # create the population operator to generate a list of individuals:\n",
        "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
        "\n",
        "    # genetic operators:\n",
        "    toolbox.register('evaluate', train_evaluate)\n",
        "    toolbox.register('select', tools.selTournament, tournsize = 2)\n",
        "    # toolbox.register('mutate', tools.mutFlipBit, indpb = 0.11)\n",
        "    toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=DOWN, up=UP, eta=CROWDING_FACTOR, indpb=1.0/DIMS)\n",
        "    toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=DOWN, up=UP, eta=CROWDING_FACTOR)\n",
        "    # toolbox.register('mate', tools.cxUniform, indpb = 0.5)\n",
        "    \n",
        "    # create initial population (generation 0):\n",
        "    population = toolbox.population(n=population_size)\n",
        "\n",
        "    # prepare the statistics object:\n",
        "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats.register(\"min\", np.min)\n",
        "    stats.register(\"avg\", np.mean)\n",
        "    stats.register(\"max\", np.max)\n",
        "\n",
        "    # define the hall-of-fame object:\n",
        "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)\n",
        "\n",
        "    # Genetic Algorithm flow with elitism:\n",
        "    population, logbook = eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
        "                                              ngen=max_generations, stats=stats, halloffame=hof, verbose=True)\n",
        "\n",
        "    # print info for best solution found:\n",
        "    best = hof.items[0]\n",
        "    print(\"-- Best Individual = \", best)\n",
        "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
        "\n",
        "    # extract statistics:\n",
        "    minFitnessValues, meanFitnessValues, maxFitnessValues = logbook.select(\"min\", \"avg\", \"max\")\n",
        "\n",
        "    # plot statistics:\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.plot(minFitnessValues, color='blue', label=\"Min\")\n",
        "    plt.plot(meanFitnessValues, color='green', label=\"Mean\")\n",
        "    plt.plot(maxFitnessValues, color='red', label=\"Max\")\n",
        "    plt.xlabel('Generation'); plt.ylabel('Max / Min / Average Fitness')\n",
        "    plt.legend()\n",
        "    plt.title('Max, Min and Average fitness over Generations')\n",
        "    plt.show()\n",
        "    \n",
        "    best_population = tools.selBest(population,k = k)\n",
        "    return best_population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ZV3VdbnIulP",
        "outputId": "1f9337cf-205d-469d-9357-c23ae90d221a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------- Starting trial: 1 ---------------\n",
            "Deep layers: 3 , Number of neurons: 150 , Learning rate: 0.0001 , Batch size: 8\n",
            "241/241 [==============================] - 1s 2ms/step - loss: 1.4904e-04 - mean_squared_error: 1.4904e-04\n",
            "Loss: 0.00014904465933796018 , Elapsed time: 503.5942060947418\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 2 ---------------\n",
            "Deep layers: 5 , Number of neurons: 200 , Learning rate: 0.001 , Batch size: 8\n",
            "Restoring model weights from the end of the best epoch: 16.\n",
            "Epoch 21: early stopping\n",
            "241/241 [==============================] - 1s 2ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
            "Loss: 0.0026349066756665707 , Elapsed time: 133.89696884155273\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 3 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 1e-05 , Batch size: 4\n",
            "241/241 [==============================] - 1s 2ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
            "Loss: 0.0020840398501604795 , Elapsed time: 863.4078118801117\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 4 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 5.0291e-05 - mean_squared_error: 5.0291e-05\n",
            "Loss: 5.029121894040145e-05 , Elapsed time: 860.3396227359772\n",
            "-------------------------------------------------\n",
            "\n",
            "gen\tnevals\tmin        \tavg       \tmax       \n",
            "0  \t4     \t5.02912e-05\t0.00122957\t0.00263491\n",
            "\n",
            "--------------- Starting trial: 5 ---------------\n",
            "Deep layers: 4 , Number of neurons: 150 , Learning rate: 0.0001 , Batch size: 8\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 7.9099e-05 - mean_squared_error: 7.9099e-05\n",
            "Loss: 7.909887790447101e-05 , Elapsed time: 623.6097583770752\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 6 ---------------\n",
            "Deep layers: 2 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Loss: 0.0010892855934798717 , Elapsed time: 803.5793855190277\n",
            "-------------------------------------------------\n",
            "\n",
            "1  \t2     \t5.02912e-05\t0.000317242\t0.00108929\n",
            "2  \t0     \t5.02912e-05\t5.02912e-05\t5.02912e-05\n",
            "\n",
            "--------------- Starting trial: 7 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 2ms/step - loss: 1.2233e-04 - mean_squared_error: 1.2233e-04\n",
            "Loss: 0.0001223312137881294 , Elapsed time: 863.5055487155914\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 8 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 1.8297e-04 - mean_squared_error: 1.8297e-04\n",
            "Loss: 0.0001829742977861315 , Elapsed time: 847.1385245323181\n",
            "-------------------------------------------------\n",
            "\n",
            "3  \t2     \t5.02912e-05\t0.000101472\t0.000182974\n",
            "\n",
            "--------------- Starting trial: 9 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 9.1885e-05 - mean_squared_error: 9.1885e-05\n",
            "Loss: 9.18847435968928e-05 , Elapsed time: 862.1716940402985\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 10 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 2ms/step - loss: 4.4153e-05 - mean_squared_error: 4.4153e-05\n",
            "Loss: 4.415338844410144e-05 , Elapsed time: 855.0113489627838\n",
            "-------------------------------------------------\n",
            "\n",
            "\n",
            "--------------- Starting trial: 11 ---------------\n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n",
            "241/241 [==============================] - 1s 3ms/step - loss: 1.2393e-04 - mean_squared_error: 1.2393e-04\n",
            "Loss: 0.00012393234646879137 , Elapsed time: 863.4129157066345\n",
            "-------------------------------------------------\n",
            "\n",
            "4  \t3     \t4.41534e-05\t7.75654e-05\t0.000123932\n",
            "-- Best Individual =  [4, 50, 0.0001, 4]\n",
            "-- Best Fitness =  5.029121894040145e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total elapsed time: 134.66722090244292 minutes\n"
          ]
        }
      ],
      "source": [
        "population_size = 4   # max of individuals per generation\n",
        "max_generations = 4   # number of generations\n",
        "gene_length = 4       # lenght of the gene, depends on how many hyperparameters are tested \n",
        "\n",
        "k = 1;                # num. of finalist individuals\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    t = time.time(); \n",
        "    datos = [];\n",
        "    ss = [i for i in range(1,population_size*(max_generations+1))]\n",
        "    best_population = geneticAlgorithm_with_elitism(population_size, max_generations, gene_length, k)\n",
        "    print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E9J0x5YzIulR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7572f9-1fc1-4b5a-bb5d-1dbf69ba4c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k= 1 \n",
            "Deep layers: 4 , Number of neurons: 50 , Learning rate: 0.0001 , Batch size: 4\n"
          ]
        }
      ],
      "source": [
        "best_deep_layers   = []\n",
        "best_num_units     = []\n",
        "best_learning_rate = []\n",
        "best_batch_size    = []\n",
        "# best_activation_f  = []\n",
        "# best_f_names       = []\n",
        "\n",
        "t = 0\n",
        "\n",
        "for bi in best_population:\n",
        "    deep_layers   = bi[0]  \n",
        "    num_units     = bi[1]\n",
        "    learning_rate = bi[2]   \n",
        "    batch_size    = bi[3]    \n",
        "#     activation_f  = bi[4]  \n",
        "    t += 1 \n",
        "    \n",
        "    best_deep_layers.append(deep_layers)\n",
        "    best_num_units.append(num_units)\n",
        "    best_learning_rate.append(learning_rate)\n",
        "    best_batch_size.append(batch_size)\n",
        "#     best_activation_f.append(activation_f)\n",
        "#     best_f_names.append(activation_f)\n",
        "    \n",
        "    print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1], ', Learning rate:', best_learning_rate[-1],', Batch size:', best_batch_size[-1])\n",
        "    # print('k=',t,'\\nDeep layers:', best_deep_layers[-1], ', Number of neurons:', best_num_units[-1], ', Learning rate:', best_learning_rate[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vgMBb6ZDIulS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "b90122a7-ad1a-439e-eece-b63dc8e219df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Deep layers  Num units  Learning rate  Batch size      Loss     Score  \\\n",
              "0             4         50        0.00010           4  0.000044  0.000044   \n",
              "1             4         50        0.00010           4  0.000050  0.000050   \n",
              "2             4        150        0.00010           8  0.000079  0.000079   \n",
              "3             4         50        0.00010           4  0.000092  0.000092   \n",
              "4             4         50        0.00010           4  0.000122  0.000122   \n",
              "5             4         50        0.00010           4  0.000124  0.000124   \n",
              "6             3        150        0.00010           8  0.000149  0.000149   \n",
              "7             4         50        0.00010           4  0.000183  0.000183   \n",
              "8             2         50        0.00010           4  0.001089  0.001089   \n",
              "9             4         50        0.00001           4  0.002084  0.002084   \n",
              "10            5        200        0.00100           8  0.002635  0.002635   \n",
              "\n",
              "    Elapsed time  \n",
              "0     855.011349  \n",
              "1     860.339623  \n",
              "2     623.609758  \n",
              "3     862.171694  \n",
              "4     863.505549  \n",
              "5     863.412916  \n",
              "6     503.594206  \n",
              "7     847.138525  \n",
              "8     803.579386  \n",
              "9     863.407812  \n",
              "10    133.896969  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f7cea36-461d-48a5-9862-5a4c1fb54bdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Deep layers</th>\n",
              "      <th>Num units</th>\n",
              "      <th>Learning rate</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Score</th>\n",
              "      <th>Elapsed time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>855.011349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>860.339623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>623.609758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>862.171694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>863.505549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>863.412916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>150</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>503.594206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>847.138525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>803.579386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>4</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>863.407812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>200</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>8</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>133.896969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f7cea36-461d-48a5-9862-5a4c1fb54bdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f7cea36-461d-48a5-9862-5a4c1fb54bdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f7cea36-461d-48a5-9862-5a4c1fb54bdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "filename = \"historial_genetic_ecsdiff.txt\"\n",
        "df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Batch size\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
        "# df = pd.DataFrame(datos, columns = [\"Deep layers\", \"Num units\", \"Learning rate\", \"Loss\", \"Score\", \"Elapsed time\"])\n",
        "\n",
        "df.sort_values(by=[\"Loss\", \"Elapsed time\"], ascending=[True, True], ignore_index=True, inplace=True)\n",
        "\n",
        "df.to_csv(filename, header=True, index=False, sep='\\t', mode='w') # a=append, w=overwrite\n",
        "df.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NCaTIHYJIulT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51d90f2-c885-4b00-b495-f9ac18f3f692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time 134.661 minutes\n"
          ]
        }
      ],
      "source": [
        "total_time = float(np.sum(df[[\"Elapsed time\"]])/60)\n",
        "\n",
        "print(\"Elapsed time {:.3f} minutes\".format(total_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qh947Ib9IulW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "genetic_hyp_ecs-diff.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}